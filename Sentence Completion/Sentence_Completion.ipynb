{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Completion\n",
    "This notebook is used for a final project as a part of the CS 4980 Natural Language Processing course at the Milwaukee School of Engineering during the spring term of 2023. This notebook was created by [Grant Fass](grantfass@gmail.com) and [Nicholas Kaja](kajan@msoe.edu). The following notebook will explore the problem of natural language sentence completion. This notebook can also be reached directly through the following GitHub repository: [https://github.com/GrantFass/NLP/tree/main/Sentence%20Completion](https://github.com/GrantFass/NLP/tree/main/Sentence%20Completion)\n",
    "\n",
    "Natural language sentence completion involves determining what word best fits in a blank present in a sentence. This type of question is typically found on the Scholastic Aptitude Test (SAT). It is useful because it can measure the performance of a language model (LM) on questions that educational experts deem important. LMs that perform well on this type of problem will likely perform better on broader tasks.\n",
    "\n",
    "The primary method for forming a sentence completion model is to compute the probability of each possible sentence tehn choose the most probable option. This probability computation can be done using n-grams, Latent Semantic Analysis (LSA), and Syntactic Dependency Trees. Some research has also been done into combining these with methods of preserving long-range dependencies in the sentences. Of these options, N-grams is one of the easiest starting points due to its ease of implementation and understanding. N-grams also allow for sufficient variations over the base model such as different N-gram algorithms, different values of N, and different methods of tokenization.\n",
    "\n",
    "We will be constructing our models from a dataset of Khan Academy lecture transcripts. This dataset was scraped using BeautifulSoup during January of 2023 by Nicholas Kaja as a part of a senior design project. The performance of our model will be evaluated on a [SAT Question Dataset](https://github.com/ctr4si/sentence-completion/tree/master/data/completion). After evaluation, we plan to take our best performing model and apply it to sentence generation. This will allow us to get a better feel for how well it performs. Once our model is working, we also plan to implement some additional features such as Named Entity Recognition (NER). If there is enough time we also plan to investigate using the [OpenAI tokenizer](https://platform.openai.com/tokenizer) instead of the [NLTK Word Tokenizer](https://www.nltk.org/api/nltk.tokenize.html) or the [SpaCy Tokenizer](https://spacy.io/api/tokenizer). The OpenAI tokenizer has a [python package found on github](https://github.com/openai/tiktoken).\n",
    "\n",
    "For more information please see the Data Collection And Processing document as well as the Project Background document. Both of these documents can be found in the repository under the Sentence Completion directory.\n",
    "\n",
    "## Pip Installations\n",
    "The below magic command should install all of the required python packages to run this project. If it does not run successfully please try to run the command through an admin shell instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\python310\\lib\\site-packages (from -r requirements.txt (line 1)) (4.11.2)\n",
      "Requirement already satisfied: contractions in c:\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (0.1.73)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: nltk in c:\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 5)) (1.24.2)\n",
      "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (from -r requirements.txt (line 6)) (1.5.3)\n",
      "Requirement already satisfied: scikit_learn in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 7)) (1.2.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 8)) (0.12.2)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from -r requirements.txt (line 9)) (4.64.1)\n",
      "Requirement already satisfied: Unidecode in c:\\python310\\lib\\site-packages (from -r requirements.txt (line 10)) (1.3.6)\n",
      "Requirement already satisfied: ipywidgets in c:\\python310\\lib\\site-packages (from -r requirements.txt (line 11)) (8.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python310\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 1)) (2.3.2.post1)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\python310\\lib\\site-packages (from contractions->-r requirements.txt (line 2)) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\python310\\lib\\site-packages (from textsearch>=0.0.21->contractions->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: anyascii in c:\\python310\\lib\\site-packages (from textsearch>=0.0.21->contractions->-r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (6.16.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in c:\\python310\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (4.0.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (5.5.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (8.5.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in c:\\python310\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (3.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (24.0.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (1.5.6)\n",
      "Requirement already satisfied: packaging in c:\\python310\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (21.3)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (6.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (1.6.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (7.4.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (5.9.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.7.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.5.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.18.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (3.0.31)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (2.13.0)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.4.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (4.11.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (0.4)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (304)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.37.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python310\\lib\\site-packages (from nltk->-r requirements.txt (line 4)) (2022.10.31)\n",
      "Requirement already satisfied: click in c:\\python310\\lib\\site-packages (from nltk->-r requirements.txt (line 4)) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from nltk->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas->-r requirements.txt (line 6)) (2022.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from scikit_learn->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\python310\\lib\\site-packages (from scikit_learn->-r requirements.txt (line 7)) (1.8.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (2.0.8)\n",
      "Requirement already satisfied: executing in c:\\users\\fassg\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt --user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This cell contains the imports and some setup functions. This is mostly generalized which means there are extra imports as of now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fassg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import nltk.data\n",
    "import re\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import unidecode\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "nltk.download([\n",
    "\"names\",\n",
    "\"stopwords\",\n",
    "\"state_union\",\n",
    "\"twitter_samples\",\n",
    "\"movie_reviews\",\n",
    "\"averaged_perceptron_tagger\",\n",
    "\"vader_lexicon\",\n",
    "\"punkt\",\n",
    "])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "encoder = LabelEncoder()\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "tqdm.pandas()\n",
    "n = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading  \n",
    "This section is used to load in all of the training data for the vocabulary. This comes from the 5 csv files of Khan Academy lectures. These files are all combined into a single dataframe for easier use and analysis. In the future we may need to include other sources of data such as ted talks or even ebooks in order to widen our vocabulary.\n",
    "\n",
    "We also load in the SAT dataset here. This is a short dataset that we are primarily using as our testing set. The goal here is to guess which response option, out of five, is the correct response for a fill-in-the-blank SAT question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8261 entries, 0 to 2789\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   course       8261 non-null   object\n",
      " 1   unit         8261 non-null   object\n",
      " 2   lesson       8261 non-null   object\n",
      " 3   video_title  8261 non-null   object\n",
      " 4   about        8261 non-null   object\n",
      " 5   transcript   8261 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 451.8+ KB\n"
     ]
    }
   ],
   "source": [
    "computing_df = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Computing.csv\")\n",
    "computing_df = computing_df.dropna()\n",
    "\n",
    "economics_df = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Economics.csv\")\n",
    "economics_df = economics_df.dropna()\n",
    "\n",
    "humanities_df = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Humanities.csv\")\n",
    "humanities_df = humanities_df.dropna()\n",
    "\n",
    "math_df = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Math.csv\")\n",
    "math_df = math_df.dropna()\n",
    "\n",
    "science_df = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Science.csv\")\n",
    "science_df = science_df.dropna()\n",
    "\n",
    "khan_dfs = [computing_df, economics_df, humanities_df, math_df, science_df]\n",
    "khan = pd.concat(khan_dfs, axis=0)\n",
    "khan.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152 entries, 0 to 151\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        152 non-null    int64 \n",
      " 1   ans       152 non-null    object\n",
      " 2   question  152 non-null    object\n",
      " 3   a)        152 non-null    object\n",
      " 4   b)        152 non-null    object\n",
      " 5   c)        152 non-null    object\n",
      " 6   d)        152 non-null    object\n",
      " 7   e)        152 non-null    object\n",
      " 8   year      152 non-null    int64 \n",
      " 9   sec       152 non-null    int64 \n",
      " 10  num       152 non-null    int64 \n",
      " 11  diff      152 non-null    object\n",
      " 12  blanks    152 non-null    int64 \n",
      "dtypes: int64(5), object(8)\n",
      "memory usage: 15.6+ KB\n"
     ]
    }
   ],
   "source": [
    "sat = pd.read_csv(\"Datasets\\\\SAT_Question_Dataset.csv\")\n",
    "sat.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "This section is dedicated to cleaning up some of our vocabulary dataset before it is used to create the vocabulary. We have decided, for simplicity, to remove the first sentence of every transcript in the dataset. This will allow us to easily remove all of the tagging information such as \"[Instructor]\" and \"- Speaker 1:\". Most of the first sentences are greetings and introductions. As such they are not necessarily as important to answering the SAT question dataset. We have also elected to expand contractions, remove html tags, remove quotes, and replace accented characters.\n",
    "\n",
    "The same general cleaning method is run over our testing data as well. The first sentence removal is not performed on the testing data.\n",
    "\n",
    "[Note] Before this section, as a part of the cleaning, we will want to perform SpaCy NER. Use SpaCy NER to identify the multi-word-expressions then use the [nltk.tokenize.mwe module](https://www.nltk.org/api/nltk.tokenize.mwe.html) to combine the tokens - Grant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3758d6fb4840480da5f8bd8ca1d08610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab109044dc143b88667a9df97a7c4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>unit</th>\n",
       "      <th>lesson</th>\n",
       "      <th>video_title</th>\n",
       "      <th>about</th>\n",
       "      <th>transcript</th>\n",
       "      <th>clean_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer programming</td>\n",
       "      <td>Intro to JS: Drawing &amp; Animation</td>\n",
       "      <td>Intro to programming</td>\n",
       "      <td>What is Programming?</td>\n",
       "      <td>Programming is the process of creating a set o...</td>\n",
       "      <td>Hi, welcome to programming! If you've never le...</td>\n",
       "      <td>If you have never learned to program before, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer programming</td>\n",
       "      <td>Intro to JS: Drawing &amp; Animation</td>\n",
       "      <td>Coloring</td>\n",
       "      <td>The Power of the Docs</td>\n",
       "      <td>Created by Pamela Fox.</td>\n",
       "      <td>Voiceover: Ok so you've\\r\\nmade a few programs...</td>\n",
       "      <td>Is it width and height, or is it height and wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Computer programming</td>\n",
       "      <td>Intro to HTML/CSS: Making webpages</td>\n",
       "      <td>Further learning</td>\n",
       "      <td>HTML validation</td>\n",
       "      <td>Learn how to validate your webpages with the W...</td>\n",
       "      <td>- [Voiceover] On Khan Academy, we pop up the o...</td>\n",
       "      <td>But we only tell you about the big things. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Computer programming</td>\n",
       "      <td>Intro to SQL: Querying and managing data</td>\n",
       "      <td>SQL basics</td>\n",
       "      <td>Welcome to SQL</td>\n",
       "      <td>SQL is useful for creating and querying relati...</td>\n",
       "      <td>- [Instructor] The world is full of data. Ever...</td>\n",
       "      <td>Every app that you use is full of data. On Kha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computer programming</td>\n",
       "      <td>Intro to SQL: Querying and managing data</td>\n",
       "      <td>SQL basics</td>\n",
       "      <td>S-Q-L or SEQUEL?</td>\n",
       "      <td>How is it pronounced? Why? Let's discuss...</td>\n",
       "      <td>At this point, you've probably heard me\\r\\npro...</td>\n",
       "      <td>Some of you might even be mad that I am pronou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 course                                      unit  \\\n",
       "0  Computer programming          Intro to JS: Drawing & Animation   \n",
       "1  Computer programming          Intro to JS: Drawing & Animation   \n",
       "5  Computer programming        Intro to HTML/CSS: Making webpages   \n",
       "6  Computer programming  Intro to SQL: Querying and managing data   \n",
       "7  Computer programming  Intro to SQL: Querying and managing data   \n",
       "\n",
       "                 lesson            video_title  \\\n",
       "0  Intro to programming   What is Programming?   \n",
       "1              Coloring  The Power of the Docs   \n",
       "5      Further learning        HTML validation   \n",
       "6            SQL basics         Welcome to SQL   \n",
       "7            SQL basics       S-Q-L or SEQUEL?   \n",
       "\n",
       "                                               about  \\\n",
       "0  Programming is the process of creating a set o...   \n",
       "1                             Created by Pamela Fox.   \n",
       "5  Learn how to validate your webpages with the W...   \n",
       "6  SQL is useful for creating and querying relati...   \n",
       "7       How is it pronounced? Why? Let's discuss...    \n",
       "\n",
       "                                          transcript  \\\n",
       "0  Hi, welcome to programming! If you've never le...   \n",
       "1  Voiceover: Ok so you've\\r\\nmade a few programs...   \n",
       "5  - [Voiceover] On Khan Academy, we pop up the o...   \n",
       "6  - [Instructor] The world is full of data. Ever...   \n",
       "7  At this point, you've probably heard me\\r\\npro...   \n",
       "\n",
       "                                    clean_transcript  \n",
       "0  If you have never learned to program before, y...  \n",
       "1  Is it width and height, or is it height and wi...  \n",
       "5  But we only tell you about the big things. The...  \n",
       "6  Every app that you use is full of data. On Kha...  \n",
       "7  Some of you might even be mad that I am pronou...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_base(x: str):\n",
    "        # remove any html tags\n",
    "        x = BeautifulSoup(x, \"html.parser\").get_text(separator=\" \")\n",
    "        # # set all to lower\n",
    "        # x = x.lower()\n",
    "        # clean up the contractions\n",
    "        x = contractions.fix(x)\n",
    "        # remove accended characters\n",
    "        x = unidecode.unidecode(x)\n",
    "        # # remove stopwords: https://stackoverflow.com/questions/19560498/faster-way-to-remove-stop-words-in-python\n",
    "        # x = ' '.join([word for word in x.split() if word not in cachedStopWords]) # slower to use word tokenize\n",
    "        # # fix punctuation spacing\n",
    "        # x = re.sub(r'(?<=[\\.\\,\\?])(?=[^\\s])', r' ', x)\n",
    "        # # strip punctuation\n",
    "        # x = re.sub(r'[\\.\\,\\?\\\\\\/\\<\\>\\;\\:\\[\\]\\{\\}]', r'', x)\n",
    "        # strip quotes\n",
    "        x = x.replace('\\'', '').replace('\\\"', '')\n",
    "        # remove some actions\n",
    "        remove_list = ['(Laughter)', '(laughter)', '(Music)', '(music)', '(Music ends)', '(Audience cheers)', '(Applause)', '(Applause ends)', '(Applause continues)', '(Bells)', '(Trumpet)', '(Clears throat)']\n",
    "        x = ' '.join([word for word in x.split() if word not in remove_list])\n",
    "        # remove extraneous items\n",
    "        x = x.replace(' -- ', '').replace(' .. ', ' ').replace(' ... ', ' ')\n",
    "        # remove extra whitespace\n",
    "        x = ' '.join(x.strip().split())\n",
    "        # # may want to add lematization\n",
    "        # x = ' '.join([lemmatizer.lemmatize(word) for word in x.split()])\n",
    "        # remove some of the extra bracket tags\n",
    "        x = re.sub(r\"\\s{2,}\", \" \", re.sub(r\"[\\(\\[\\{][^\\)\\]\\}]*[\\)\\]\\}]\", \"\", x))\n",
    "        return x\n",
    "\n",
    "def remove_first_sentence(doc):\n",
    "    \"\"\"\n",
    "    This removes the first sentence of a document. We use this to remove all narrator / speaker tags, and\n",
    "    to remove unnecessary introductory sentences that most transcripts have\n",
    "    \"\"\"\n",
    "    return ' '.join(nltk.sent_tokenize(doc)[1:])\n",
    "\n",
    "transcripts = khan['transcript']\n",
    "transcripts = transcripts.progress_apply(remove_first_sentence)\n",
    "transcripts = transcripts.progress_apply(clean_base)\n",
    "khan['clean_transcript'] = transcripts\n",
    "khan.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dac7ac5ae754454a638f73e3e0fd061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47560a2335854639b51b5e606a2fbc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88629bded1144ff69af3050a729616c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fd8967f55243c29b5eb7db84c5abcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290a65b46956476c9ed680858fa3b998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cb44d5b85b4c18a4c91b10f89111da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ans</th>\n",
       "      <th>question</th>\n",
       "      <th>a)</th>\n",
       "      <th>b)</th>\n",
       "      <th>c)</th>\n",
       "      <th>d)</th>\n",
       "      <th>e)</th>\n",
       "      <th>year</th>\n",
       "      <th>sec</th>\n",
       "      <th>num</th>\n",
       "      <th>diff</th>\n",
       "      <th>blanks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>Much of our knowledge of dinosaurs comes from ...</td>\n",
       "      <td>Much of our knowledge of dinosaurs comes from ...</td>\n",
       "      <td>Much of our knowledge of dinosaurs comes from ...</td>\n",
       "      <td>Much of our knowledge of dinosaurs comes from ...</td>\n",
       "      <td>Much of our knowledge of dinosaurs comes from ...</td>\n",
       "      <td>Much of our knowledge of dinosaurs comes from ...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>Responding to criticism that the script was ra...</td>\n",
       "      <td>Responding to criticism that the script was ra...</td>\n",
       "      <td>Responding to criticism that the script was ra...</td>\n",
       "      <td>Responding to criticism that the script was ra...</td>\n",
       "      <td>Responding to criticism that the script was ra...</td>\n",
       "      <td>Responding to criticism that the script was ra...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "      <td>Vernal pools are among the most _____ of ponds...</td>\n",
       "      <td>Vernal pools are among the most transitory of ...</td>\n",
       "      <td>Vernal pools are among the most anachronistic ...</td>\n",
       "      <td>Vernal pools are among the most immutable of p...</td>\n",
       "      <td>Vernal pools are among the most itinerant of p...</td>\n",
       "      <td>Vernal pools are among the most ephemeral of p...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>During the 1990s, Shanghai benefited from an a...</td>\n",
       "      <td>During the 1990s, Shanghai benefited from an a...</td>\n",
       "      <td>During the 1990s, Shanghai benefited from an a...</td>\n",
       "      <td>During the 1990s, Shanghai benefited from an a...</td>\n",
       "      <td>During the 1990s, Shanghai benefited from an a...</td>\n",
       "      <td>During the 1990s, Shanghai benefited from an a...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>Many subatomic nuclear particles are _____ and...</td>\n",
       "      <td>Many subatomic nuclear particles are unstable ...</td>\n",
       "      <td>Many subatomic nuclear particles are elusive a...</td>\n",
       "      <td>Many subatomic nuclear particles are minute an...</td>\n",
       "      <td>Many subatomic nuclear particles are charged a...</td>\n",
       "      <td>Many subatomic nuclear particles are tenuous a...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id ans                                           question  \\\n",
       "0   1   e  Much of our knowledge of dinosaurs comes from ...   \n",
       "1   2   c  Responding to criticism that the script was ra...   \n",
       "2   3   e  Vernal pools are among the most _____ of ponds...   \n",
       "3   4   e  During the 1990s, Shanghai benefited from an a...   \n",
       "4   5   b  Many subatomic nuclear particles are _____ and...   \n",
       "\n",
       "                                                  a)  \\\n",
       "0  Much of our knowledge of dinosaurs comes from ...   \n",
       "1  Responding to criticism that the script was ra...   \n",
       "2  Vernal pools are among the most transitory of ...   \n",
       "3  During the 1990s, Shanghai benefited from an a...   \n",
       "4  Many subatomic nuclear particles are unstable ...   \n",
       "\n",
       "                                                  b)  \\\n",
       "0  Much of our knowledge of dinosaurs comes from ...   \n",
       "1  Responding to criticism that the script was ra...   \n",
       "2  Vernal pools are among the most anachronistic ...   \n",
       "3  During the 1990s, Shanghai benefited from an a...   \n",
       "4  Many subatomic nuclear particles are elusive a...   \n",
       "\n",
       "                                                  c)  \\\n",
       "0  Much of our knowledge of dinosaurs comes from ...   \n",
       "1  Responding to criticism that the script was ra...   \n",
       "2  Vernal pools are among the most immutable of p...   \n",
       "3  During the 1990s, Shanghai benefited from an a...   \n",
       "4  Many subatomic nuclear particles are minute an...   \n",
       "\n",
       "                                                  d)  \\\n",
       "0  Much of our knowledge of dinosaurs comes from ...   \n",
       "1  Responding to criticism that the script was ra...   \n",
       "2  Vernal pools are among the most itinerant of p...   \n",
       "3  During the 1990s, Shanghai benefited from an a...   \n",
       "4  Many subatomic nuclear particles are charged a...   \n",
       "\n",
       "                                                  e)  year  sec  num diff  \\\n",
       "0  Much of our knowledge of dinosaurs comes from ...  2001    1    1    1   \n",
       "1  Responding to criticism that the script was ra...  2001    1    2    1   \n",
       "2  Vernal pools are among the most ephemeral of p...  2001    1    3    2   \n",
       "3  During the 1990s, Shanghai benefited from an a...  2001    1    4    3   \n",
       "4  Many subatomic nuclear particles are tenuous a...  2001    1    5    3   \n",
       "\n",
       "   blanks  \n",
       "0       2  \n",
       "1       2  \n",
       "2       2  \n",
       "3       1  \n",
       "4       2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column_name in ['question', 'a)', 'b)', 'c)', 'd)', 'e)']:\n",
    "    sat[column_name] = sat[column_name].progress_apply(clean_base)\n",
    "sat.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams\n",
    "This section is used for the tokenization of our text into N-Grams. Various tokenization approaches may yield different results. As such, it is important to test different approaches here. We begin by dividing each of the transcripts into its constituent sentences. These sentences are then each tokenized using the word tokenizer provided by nltk. A start and end of sentence tag is then added to each list of tokens. Next, these tokens are used to generate all possible n-grams below a certain size threshold. Lastly, we create a frequency distribution dictionary for the n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb8faa0658041d9ab348bfe82701794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603547\n"
     ]
    }
   ],
   "source": [
    "# create a list of all of the sentences with each sentence tokenized.\n",
    "def tokenize_transcript(transcript):\n",
    "    token_document = [word_tokenize(t) for t in sent_detector.tokenize(transcript)]\n",
    "    sents = []\n",
    "    start_of_sentence = \"<sent>\"\n",
    "    end_of_sentence = \"<\\\\sent>\"\n",
    "    for sent in token_document:\n",
    "        sent.insert(0, start_of_sentence)\n",
    "        sent.append(end_of_sentence)\n",
    "        sents.append(sent)\n",
    "    return sents\n",
    "\n",
    "sents = []\n",
    "for transcript in tqdm(khan['clean_transcript']):\n",
    "    sents += tokenize_transcript(transcript)\n",
    "\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing all N-grams where N is 3 or less\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab96da5ec27741ba8fc6d7c9aefabd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/603547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frequency distribution\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "print(\"Computing all N-grams where N is %d or less\" % n)\n",
    "grams = []\n",
    "for sent in tqdm(sents):\n",
    "    for i in range(0, 3):\n",
    "        grams += list(ngrams(sent, i + 1))\n",
    "    \n",
    "print(\"Computing frequency distribution\")\n",
    "freq_dist = nltk.FreqDist(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({(',',): 633121, ('<sent>',): 603547, ('<\\\\sent>',): 603547, ('.',): 562507, ('.', '<\\\\sent>'): 562502, ('the',): 487131, ('is',): 352802, ('to',): 326556, ('of',): 275192, ('that',): 223332, ...})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist[(',',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist[('among',)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAT Dataset\n",
    "This section focuses on the processing of individual SAT questions as well as defining a prediction method for the dataset. Below is a sample approach for the prediction method.\n",
    "\n",
    "### SAT Question Prediction Approach\n",
    "Note that this approach is slightly different from what was implemented. One of the main differences is that our tokenization currently includes punctuation as its own token whereas the below example removes punctuation.\n",
    "\n",
    "\"\"\"  \n",
    "Question:  \n",
    "Responding to criticism that the script was rambling and _____, the new screenwriter revised the dialogue for greater succinctness and _____.\n",
    "\n",
    "Possible Solutions:  \n",
    "[('engaging', 'simplicity'), ('subjective', 'abiguity'), ('muddled', 'clarity'), ('terse', 'emptiness'), ('difficult', 'abstraction')]  \n",
    "\"\"\"\n",
    "\n",
    "N-gram size of 4 max\n",
    "1. Change the blanks out to something we can use to mask the individual ones later. For example, [BLANK1] and [BLANK2].\n",
    "    - esponding to criticism that the script was rambling and [BLANK1], the new screenwriter revised the dialogue for greater succinctness and [BLANK2].<\\sent>\n",
    "2. Pull out the possible sliding windows centered around each blank.\n",
    "    - blank 1\n",
    "        - n=4\n",
    "            - ('was', 'rambling', 'and', [BLANK1])\n",
    "            - ('rambling', 'and', [BLANK1], 'the')\n",
    "            - ('and', [BLANK1], 'the', 'new')\n",
    "            - ([BLANK1], 'the', 'new', 'screenwriter')\n",
    "        - n=3\n",
    "            - ('rambling', 'and', [BLANK1])\n",
    "            - ('and', [BLANK1], 'the')\n",
    "            - ([BLANK1], 'the', 'new')\n",
    "        - n=2\n",
    "            - ('and', [BLANK1])\n",
    "            - ([BLANK1], 'the')\n",
    "        - n=1\n",
    "            - ([BLANK1])\n",
    "    - blank 2\n",
    "        - n=4\n",
    "            - ('greater', 'succinctness', 'and', [BLANK2])\n",
    "            - ('succinctness', 'and', [BLANK2], <\\sent>)\n",
    "        - n=3\n",
    "            - ('succinctness', 'and', [BLANK2])\n",
    "            - ('and', [BLANK2], <\\sent>)\n",
    "        - n=2\n",
    "            - ('and', [BLANK2])\n",
    "            - ([BLANK2], <\\sent>)\n",
    "        - n=1\n",
    "            - ([BLANK2])\n",
    "3. For each of the possible solutions:\n",
    "    1. For each of the windows:\n",
    "        1. If the first or second word in the possible solution tuple is not in the vocab then discard it as a possible solution.\n",
    "        2. Replace [BLANK1] with the first item in the possible solution tuple\n",
    "        3. Replace [BLANK2] with the second item in the possible solution tuple\n",
    "        4. Lookup each of the window n-grams against the stored n-grams and determine how many times it occured.\n",
    "        5. What to do if the count for a n-gram is 0 for one word but not for another word?\n",
    "        6. Calculate the probability of each window n-gram\n",
    "        7. sum the logs of the probabilities of each window n-gram. \n",
    "    2. Determine which of the windows had the highest log likelihood and return the associated word tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute the windows\n",
      "mask indicies = [10, 22]\n",
      "[('engaging', 'simplicity'), ('subjective', 'ambiguity'), ('muddled', 'clarity'), ('terse', 'emptiness'), ('difficult', 'abstraction')]\n",
      "[['rambling', 'and', '_____0'], ['and', '_____0', ','], ['_____0', ',', 'the'], ['and', '_____0'], ['_____0', ','], ['_____0'], ['succinctness', 'and', '_____1'], ['and', '_____1', '.'], ['and', '_____1'], ['_____1', '.'], ['_____1']]\n",
      "['<sent>', 'Responding', 'to', 'criticism', 'that', 'the', 'script', 'was', 'rambling', 'and', '_____0', ',', 'the', 'new', 'screenwriter', 'revised', 'the', 'dialogue', 'for', 'greater', 'succinctness', 'and', '_____1', '.', '<\\\\sent>']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_question(question):\n",
    "    if not isinstance(question, str) or question is None:\n",
    "        return []\n",
    "    sent = word_tokenize(question)\n",
    "    start_of_sentence = \"<sent>\"\n",
    "    end_of_sentence = \"<\\\\sent>\"\n",
    "    sent.insert(0, start_of_sentence)\n",
    "    sent.append(end_of_sentence)\n",
    "    return sent\n",
    "\n",
    "def get_mask_indices(row, mask='_____'):\n",
    "    \"\"\"Returns a list containing the integer indices of where the mask occurs for a given row of the SAT dataset.\n",
    "\n",
    "    Args:\n",
    "        row : a given row of the SAT dataset\n",
    "        mask (str, optional): the mask to look for the indicies of occurance of. Defaults to '_____'.\n",
    "\n",
    "    Returns:\n",
    "        list: contains integer indices of where the mask occurs for a given row of the SAT dataset\n",
    "    \"\"\"\n",
    "    mask_indices = []\n",
    "    previous_idx = 0\n",
    "    for blank_id in range(row['blanks']):\n",
    "        idx = tokenize_question(row['question']).index(mask, previous_idx)\n",
    "        mask_indices.append(idx)\n",
    "        previous_idx = idx + 1\n",
    "    return mask_indices\n",
    "\n",
    "def extract_possible_solutions(row, mask_indices):\n",
    "    \"\"\"computes the possible solutions that can fill in the blanks for a given question in a row of the SAT dataset.\n",
    "    The possible solutions come from the a-e columns of the row while the question itself comes from the question column.\n",
    "\n",
    "    Args:\n",
    "        row (_type_): a given row of the SAT dataset.\n",
    "        mask_indices (list): list containing integer indices of where the mask occurs for a given row of the SAT dataset.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of tuples. Each tuple contains the possible solutions in their respective order to the question.\n",
    "    \"\"\"\n",
    "    possible_solutions = []\n",
    "    for i in ['a)', 'b)', 'c)', 'd)', 'e)']:\n",
    "        # print(test[i])\n",
    "        tokens = tokenize_question(row[i])\n",
    "        if tokens:\n",
    "            possible_solution = []\n",
    "            for mask_idx in mask_indices:\n",
    "                possible_solution.append(tokens[mask_idx])\n",
    "            possible_solutions.append(tuple(possible_solution))\n",
    "    return possible_solutions\n",
    "\n",
    "def get_ngrams_with_mask(mask_indices, tokenized_question, n, mask='_____'):\n",
    "    \"\"\"This method is used to compute the sliding window for the original n-gram size as well\n",
    "    as each of the subsequently smaller sizes of n. This method requires the variable 'n' to\n",
    "    be defined globally for the maximum n-gram size to look for.\n",
    "\n",
    "    Args:\n",
    "        mask_indices (list): list containing integer indices of where the mask occurs for a given row of the SAT dataset.\n",
    "        tokenized_question (list): list comprised of the individual tokens that were parsed from the input question\n",
    "        n (int): the maximum n-gram size to use.\n",
    "        mask (str, optional): the mask to look for the indicies of occurance of. Defaults to '_____'.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        list: A list containing tuples of each n-gram is returned. If more than one \n",
    "    \"\"\"\n",
    "    ranges = []\n",
    "    count = 0\n",
    "    for mask_idx in mask_indices:\n",
    "        remask = mask + str(count)\n",
    "        tokenized_question[mask_idx] = remask\n",
    "        count += 1\n",
    "        # print(\"\\nmask_idx = %d\" % mask_idx)\n",
    "        for i in range(n, 0, -1):  # for each successively smaller n-gram size\n",
    "            # print(\"n = %d\" % i)\n",
    "            upper_bound = mask_idx + 1\n",
    "            lower_bound = mask_idx - i + 1\n",
    "            if lower_bound >= 0 and upper_bound < len(tokenized_question):\n",
    "                ranges.append((lower_bound, upper_bound))\n",
    "                # print(\"range(%d, %d)\" % (lower_bound, upper_bound))\n",
    "            for j in range(1, i):  # already processed first n-gram for size i. Now process the rest where j is the offset.\n",
    "                upper_bound += 1\n",
    "                lower_bound += 1\n",
    "                if lower_bound >= 0 and upper_bound < len(tokenized_question):\n",
    "                    ranges.append((lower_bound, upper_bound))\n",
    "                    # print(\"range(%d, %d)\" % (lower_bound, upper_bound))\n",
    "    n_grams = []\n",
    "    for indices in ranges:\n",
    "        n_gram = []\n",
    "        for i in range(indices[0], indices[1]):\n",
    "            n_gram.append(tokenized_question[i])\n",
    "        n_grams.append(n_gram)\n",
    "        \n",
    "    return n_grams\n",
    "    \n",
    "    \n",
    "print(\"compute the windows\")\n",
    "test = sat.iloc[1]\n",
    "mask = \"_____\"\n",
    "mask_indices = get_mask_indices(test)\n",
    "tokenized_question = tokenize_question(test['question'])\n",
    "possible_solutions = extract_possible_solutions(test, mask_indices)\n",
    "windows = get_ngrams_with_mask(mask_indices, tokenized_question, n=3)\n",
    "print(\"mask indicies = %s\" % str(mask_indices))\n",
    "print(possible_solutions)\n",
    "print(windows)\n",
    "print(tokenized_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Answer: ('muddled', 'clarity')\n"
     ]
    }
   ],
   "source": [
    "def find_best_answer(possible_solutions, windows, freq_dist, mask='_____'):\n",
    "    \"\"\"method used to determine which one of the possible solutions is the most likely answer.\n",
    "\n",
    "    Args:\n",
    "        possible_solutions (list): list of tuples where each tuple is one of the possible solutions to fill in the blanks in the sentence.\n",
    "        windows (list): the windows of n-grams. These windows are centered around the locations of the blanks in the sentence.\n",
    "        freq_dist (dict): a dictionary where the key is a n-gram as a tuple and the value is the frequency count of the n-gram tuple.\n",
    "        mask (str, optional): the mask to look for the indicies of occurance of. Defaults to '_____'.\n",
    "\n",
    "    Returns:\n",
    "        (tuple): the tuple containing the words from the best possible solution predicted.\n",
    "    \"\"\"\n",
    "    log_likelihood_given_solution = []\n",
    "    for possible_solution in possible_solutions:  # compute the log likelihood of each possible solution.\n",
    "        # print(\"\\nGenerating Solutions For: %s\" % (possible_solution,))\n",
    "        log_likelihood = 0\n",
    "        for window in windows:  # go through each of the generated windows and find its probability.\n",
    "            for i in range(len(possible_solution)):  # replace the masks with each of the possible solution words\n",
    "                window = list(map(lambda x: x.replace(mask + str(i), possible_solution[i]), window))\n",
    "            # print(window)\n",
    "            ngram_size = len(window)\n",
    "            raw_ngram_count = freq_dist[tuple(window)]\n",
    "            if raw_ngram_count > 0:  # the ngram occurs in our corpus\n",
    "                ngram_count_of_prior = 1  # default to 1 for unigrams\n",
    "                if ngram_size > 1:  # not a unigram so we need to find the count of the 'given' ngram\n",
    "                    prior = window[0: len(window)-1]\n",
    "                    ngram_count_of_prior = freq_dist[tuple(prior)]\n",
    "                raw_probability = raw_ngram_count / ngram_count_of_prior\n",
    "                log_probability = math.log10(raw_probability)\n",
    "                log_likelihood += log_probability\n",
    "        # print(\"Log Likelihood = %.2f\" % log_likelihood)\n",
    "        log_likelihood_given_solution.append((possible_solution, log_likelihood))\n",
    "    log_likelihood_given_solution.sort(key = lambda x: x[1], reverse = True)\n",
    "    answer = log_likelihood_given_solution[0][0]\n",
    "    # print(\"Best Answer: %s\" % (answer, ))\n",
    "    # print(\"sorted likelihoods per possible solution:\\n%s\" % str(log_likelihood_given_solution))\n",
    "    return answer\n",
    "\n",
    "best_answer = find_best_answer(possible_solutions, windows, freq_dist)\n",
    "print(\"Best Answer: %s\" % (best_answer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted answer is in column c\n"
     ]
    }
   ],
   "source": [
    "def determine_prediction_based_on_best_answer(best_answer, row, mask_indices):\n",
    "    \"\"\"method to determine the column name of the best answer\n",
    "\n",
    "    Args:\n",
    "        best_answer (tuple): the tuple containing the words from the best possible solution predicted.\n",
    "        row : a row in the pandas data frame for the SAT dataset.\n",
    "        mask_indices (list): list containing the indices of where the mask (blanks) occur.\n",
    "\n",
    "    Returns:\n",
    "        str: the column name corresponding to the best answer.\n",
    "    \"\"\"\n",
    "    for col in ['a)', 'b)', 'c)', 'd)', 'e)']:\n",
    "        tokens = tokenize_question(row[col])\n",
    "        result = True\n",
    "        count = 0\n",
    "        for mask_idx in mask_indices:\n",
    "            if tokens[mask_idx] != best_answer[count]:\n",
    "                result = False\n",
    "            count += 1\n",
    "        if result:\n",
    "            return col.replace(\")\", \"\")\n",
    "        \n",
    "prediction = determine_prediction_based_on_best_answer(best_answer, test, mask_indices)\n",
    "print(\"The predicted answer is in column %s\" % prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['c']\n",
      "True Value: ['c']\n",
      "[ACCURACY]     : 1.000\n",
      "[PRECISION]    : 1.000\n",
      "[RECALL]       : 1.000\n",
      "[F1-SCORE]     : 1.000\n"
     ]
    }
   ],
   "source": [
    "def predict(row):\n",
    "    mask = \"_____\"\n",
    "    mask_indices = get_mask_indices(row, mask=mask)\n",
    "    tokenized_question = tokenize_question(row['question'])\n",
    "    possible_solutions = extract_possible_solutions(row, mask_indices)\n",
    "    windows = get_ngrams_with_mask(mask_indices, tokenized_question, n=3, mask=mask)\n",
    "    best_answer = find_best_answer(possible_solutions, windows, freq_dist, mask=mask)  # note that freq_dist is a global here.\n",
    "    prediction = determine_prediction_based_on_best_answer(best_answer, row, mask_indices)\n",
    "    return prediction\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    print(\"%-15s: %.3f\" % (\"[ACCURACY]\", accuracy_score(y_true, y_pred)))\n",
    "    print(\"%-15s: %.3f\" % (\"[PRECISION]\", precision_score(y_true, y_pred, average='weighted')))\n",
    "    print(\"%-15s: %.3f\" % (\"[RECALL]\", recall_score(y_true, y_pred, average='weighted')))\n",
    "    print(\"%-15s: %.3f\" % (\"[F1-SCORE]\", f1_score(y_true, y_pred, average='weighted')))    \n",
    "\n",
    "# test the prediction method.\n",
    "prediction = [predict(test)]\n",
    "print(\"Prediction: %s\" % prediction)\n",
    "true_value = [test['ans']]\n",
    "print(\"True Value: %s\" % true_value)\n",
    "score(true_value, prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "This section is used to actually compute the predictions for our test data and our given input frequency distribution. The results of the prediction are then evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a546291b692e4819850f9c970fc3130a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACCURACY]     : 0.158\n",
      "[PRECISION]    : 0.159\n",
      "[RECALL]       : 0.158\n",
      "[F1-SCORE]     : 0.155\n"
     ]
    }
   ],
   "source": [
    "# skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=False)\n",
    "# for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "predictions = sat.progress_apply(lambda row: predict(row), axis=1)\n",
    "predictions\n",
    "true_values = sat['ans']\n",
    "score(true_values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.19      0.25      0.21        32\n",
      "           b       0.15      0.11      0.13        37\n",
      "           c       0.15      0.19      0.17        27\n",
      "           d       0.08      0.09      0.09        22\n",
      "           e       0.19      0.15      0.17        34\n",
      "\n",
      "    accuracy                           0.16       152\n",
      "   macro avg       0.15      0.16      0.15       152\n",
      "weighted avg       0.16      0.16      0.16       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1f160eb7430>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAIjCAYAAAAwQQ7gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf4ElEQVR4nO3dd3gUVdsG8HvTNnU3CaRCCEmA0IvIi/QAAioioH5IUUIVFKRXeUMVgiBSlap0UERBRVGRKtIVkCaEUBJqaOl993x/YPZlSYIJmbLZvX/XNdfFzs6eefawO3n2mTNnNEIIASIiIiKSlJ3aARARERFZIyZZRERERDJgkkVEREQkAyZZRERERDJgkkVEREQkAyZZRERERDJgkkVEREQkAyZZRERERDJgkkVEREQkAyZZNiAmJgZt27aFXq+HRqPB1q1bJW3/ypUr0Gg0WLVqlaTtlmYRERGIiIiQrL3U1FT069cP/v7+0Gg0GDZsmGRtE1kyuY4vUn9HiQrCJEshsbGxGDBgAEJDQ+Hs7AydTocmTZpg/vz5yMjIkHXfkZGROHXqFKZPn461a9fi2WeflXV/SurVqxc0Gg10Ol2B/RgTEwONRgONRoOPPvqo2O3fuHEDkydPxokTJySI9unNmDEDq1atwjvvvIO1a9firbfeknV/2dnZmD9/PurVqwedTgdPT0/UqFEDb7/9Nv7+++8CX3Pu3DloNBo4OzsjMTHRtD7v/+jfll69esn6noorPT0dkydPxp49e9QOhZ7S2bNnMXnyZFy5ckXtUMhGOagdgC344Ycf8H//93/QarXo2bMnatasiezsbOzfvx+jR4/GmTNnsGzZMln2nZGRgYMHD2LChAkYPHiwLPsIDg5GRkYGHB0dZWn/3zg4OCA9PR3ff/89unTpYvbc+vXr4ezsjMzMzKdq+8aNG5gyZQoqVqyIunXrFvl1v/zyy1PtrzC7du3Cc889h0mTJknabmFee+01bN++Hd26dUP//v2Rk5ODv//+G9u2bUPjxo1RtWrVfK9Zt24d/P398eDBA2zevBn9+vUDAAwYMADPP/+8abvLly9j4sSJePvtt9GsWTPT+rCwMPnfWDGkp6djypQpAMCKRyl19uxZTJkyBREREahYsaLZc1J/R4kKwiRLZpcvX0bXrl0RHByMXbt2ISAgwPTcoEGDcPHiRfzwww+y7f/OnTsAAE9PT9n2kVe9UItWq0WTJk2wcePGfEnWhg0b0L59e3z99deKxJKeng5XV1c4OTlJ2m5CQgKqV68uWXu5ubkwGo0Fxnn06FFs27YN06dPx/vvv2/23KJFi8yqVHmEENiwYQO6d++Oy5cvY/369aYkq1GjRmjUqJFp22PHjmHixIlo1KgR3nzzTcneE1FxSP0dJSqQIFkNHDhQABC///57kbbPyckRU6dOFaGhocLJyUkEBweL8ePHi8zMTLPtgoODRfv27cVvv/0mGjRoILRarQgJCRGrV682bTNp0iQBwGwJDg4WQggRGRlp+vej8l7zqF9++UU0adJE6PV64ebmJqpUqSLGjx9vev7y5csCgFi5cqXZ63bu3CmaNm0qXF1dhV6vF6+88oo4e/ZsgfuLiYkRkZGRQq/XC51OJ3r16iXS0tL+tb8iIyOFm5ubWLVqldBqteLBgwem544cOSIAiK+//loAELNnzzY9d+/ePTFy5EhRs2ZN4ebmJjw8PMQLL7wgTpw4Ydpm9+7d+frv0ffZokULUaNGDXHs2DHRrFkz4eLiIoYOHWp6rkWLFqa2evbsKbRabb7337ZtW+Hp6SmuX79e4PsrLIbLly8LIYS4ffu26NOnj/D19RVarVbUrl1brFq1yqyNvP+f2bNni7lz54rQ0FBhZ2cnjh8/XuA+N27cKACIPXv2PKHnzf32228CgDhy5Ij48ssvhZ2dnYiPjy9w26NHjxb4eXmSmzdvil69eoly5coJJycn4e/vL1555RVTP+T58ccfTZ85d3d38dJLL4nTp0+bbZP3mbl27Zro2LGjcHNzE2XLlhUjR44Uubm5Qoj/9dnjy6RJk0ztnDt3Trz22mvCy8tLaLVaUb9+ffHtt9+a7WvlypUCgNi/f78YPny4KFu2rHB1dRWdOnUSCQkJ+d7njz/+KJo3by7c3d2Fh4eHePbZZ8X69evNtjl06JBo166d0Ol0wsXFRTRv3lzs37+/SP2YkZEhJk2aJCpXriy0Wq3w9/cXnTt3FhcvXjRtk5qaKkaMGCHKly8vnJycRJUqVcTs2bOF0Wg0awuAGDRokNi0aZOoVq2acHZ2Fs8995z466+/hBBCLFmyRISFhQmtVitatGiR7//q0e9Po0aNhLOzs6hYsaJYvHix2XaFHV/+rf/z+v7xZffu3ab9P/odFaL436elS5eajtXPPvusOHLkSJH+H8h2MMmSWbly5URoaGiRt4+MjBQAxOuvvy4++eQT0bNnTwFAdOrUyWy74OBgER4eLvz8/MT7778vFi1aJJ555hmh0WhMf1ROnjwp5s6dKwCIbt26ibVr14otW7aY9lOUJOv06dOmA8j8+fPFkiVLxKhRo0Tz5s1N2xR0ENyxY4dwcHAQVapUEbNmzRJTpkwRZcuWFV5eXmYH27z91atXT7z66qvi008/Ff369RMAxJgxY4rUX25ubiI5OVk4OzuLzz77zPTcsGHDRNWqVc0OinmOHj0qwsLCxLhx48TSpUvF1KlTRbly5YRerzclPLdu3RJTp04VAMTbb78t1q5dK9auXStiY2OFEA8P0v7+/sLHx0e89957YunSpWLr1q2m5x49gD948ECUL19eNGjQwPSHfMmSJQKAWLt2baHv79atW2Lt2rWibNmyom7duqYYUlNTRXp6uqhWrZpwdHQUw4cPFwsWLBDNmjUTAMS8efPy/f9Ur15dhIaGipkzZ4q5c+eKq1evFrjPAwcOCACif//+Iicn51//D4R4+GMiLCxMCCFEenq6cHd3F7NmzSpw26dJsho3biz0er3473//K1asWCFmzJghWrZsKfbu3WvaZs2aNUKj0YgXXnhBLFy4UHz44YeiYsWKwtPT0+wzFxkZKZydnUWNGjVEnz59xOLFi8Vrr70mAIhPP/1UCPEw0Vi8eLEAIDp37mzq95MnTwohHn4v9Hq9qF69uvjwww/FokWLRPPmzYVGoxHffPONaV95f+jr1asnWrVqJRYuXChGjhwp7O3tRZcuXcze48qVK4VGoxE1a9YU06dPF5988ono16+feOutt0zb7Ny5Uzg5OYlGjRqJOXPmiLlz54ratWsLJycncfjw4Sf2YW5urmjdurUAILp27SoWLVokoqOjRatWrUyfW6PRKFq1aiU0Go3o16+fWLRokejQoYMAIIYNG2bWHgBRu3ZtERQUJGbOnClmzpwp9Hq9qFChgli0aJGoXr26mDNnjvjvf/8rnJycRMuWLc1e36JFCxEYGCh8fX3F4MGDxYIFC0TTpk0FALPvcUHHl6L0f2xsrBgyZIgAIN5//33T/+GtW7dM+3/0O1rc71O9evVEpUqVxIcffihmzZolypYtK8qXLy+ys7Of+P9AtoVJloySkpIEANGxY8cibX/ixAkBQPTr189s/ahRowQAsWvXLtO64OBgAUDs27fPtC4hIUFotVoxcuRI07qCEgwhip5k5SVpd+7cKTTugg6CdevWFb6+vuLevXumdSdPnhR2dnaiZ8+e+fbXp08fszY7d+4sypQpU+g+H30fbm5uQgghXn/9ddG6dWshhBAGg0H4+/uLKVOmFNgHmZmZwmAw5HsfWq1WTJ061bTuSQlBixYtBACxZMmSAp97/Ffyzz//LACIDz74QFy6dEm4u7vnS54Lk1e5fNS8efMEALFu3TrTuuzsbNGoUSPh7u4ukpOTTe8LgNDpdAVWTx5nNBpN783Pz09069ZNfPLJJ4UmZdnZ2aJMmTJiwoQJpnXdu3cXderUKXD74iZZDx48KPAz/KiUlBTh6ekp+vfvb7b+1q1bQq/Xm63P+yHz6P+zEELUq1dP1K9f3/T4zp07+apXeVq3bi1q1aplVmE2Go2icePGonLlyqZ1eUnW888/b1YJGj58uLC3txeJiYlCCCESExOFh4eHaNiwocjIyDDbV97rjEajqFy5smjXrp1ZW+np6SIkJES0adOm0P4RQojPP/9cABAff/xxvufy2tu6davpM/qo119/XWg0GrOKFwCh1WrNEtilS5cKAMLf39/0+RNCiPHjx5tVYIX43/dnzpw5pnVZWVmmY0deslLQ8aWo/f/VV1+ZVa8e9fh3tLjfpzJlyoj79++btv32228FAPH999/n2xfZLl5dKKPk5GQAgIeHR5G2//HHHwEAI0aMMFs/cuRIAMg3dqt69epmA4d9fHwQHh6OS5cuPXXMj8sby/Xtt9/CaDQW6TU3b97EiRMn0KtXL3h7e5vW165dG23atDG9z0cNHDjQ7HGzZs1w7949Ux8WRffu3bFnzx7cunULu3btwq1bt9C9e/cCt9VqtbCze/jxNxgMuHfvHtzd3REeHo4///yzyPvUarXo3bt3kbZt27YtBgwYgKlTp+LVV1+Fs7Mzli5dWuR9Pe7HH3+Ev78/unXrZlrn6OiIIUOGIDU1FXv37jXb/rXXXoOPj8+/tqvRaPDzzz/jgw8+gJeXFzZu3IhBgwYhODgYb7zxRr4xWdu3b8e9e/fM4ujWrRtOnjyJM2fOPPX7y+Pi4gInJyfs2bMHDx48KHCbHTt2IDExEd26dcPdu3dNi729PRo2bIjdu3fne01Bn7mifHfu37+PXbt2oUuXLkhJSTHt6969e2jXrh1iYmJw/fp1s9e8/fbb0Gg0ZvsyGAy4evWqKf6UlBSMGzcu3/jGvNedOHECMTEx6N69O+7du2fab1paGlq3bo19+/Y98Tv69ddfo2zZsnjvvffyPZe3jx9//BH29vYYMmSI2fMjR46EEALbt283W9+6dWuzAeUNGzYE8PCz9uhxL2/94/3r4OCAAQMGmB47OTlhwIABSEhIwB9//FHg+3ia/i+K4n6f3njjDXh5eZke5x2LpTz+UunHJEtGOp0OAJCSklKk7a9evQo7OztUqlTJbL2/vz88PT1NB+Q8FSpUyNeGl5dXoX+InsYbb7yBJk2aoF+/fvDz80PXrl2xadOmJx7M8+IMDw/P91y1atVMfxge9fh7yTt4Fee9vPTSS/Dw8MCXX36J9evXo0GDBvn6Mo/RaMTcuXNRuXJlaLValC1bFj4+Pvjrr7+QlJRU5H2WK1euWANoP/roI3h7e+PEiRNYsGABfH19i/zax129ehWVK1c2JYt5qlWrZnr+USEhIUVuW6vVYsKECTh37hxu3LiBjRs34rnnnsOmTZvyXaW6bt06hISEQKvV4uLFi7h48SLCwsLg6uqK9evXP+W7M4/lww8/xPbt2+Hn54fmzZtj1qxZuHXrlmmbmJgYAECrVq3g4+Njtvzyyy9ISEgwa9PZ2TlfwlnU787FixchhEBUVFS+feVd/fn4/v7t8x0bGwsAqFmzZqH7zXuPkZGR+fa7YsUKZGVlPfGzGxsbi/DwcDg4FH6909WrVxEYGJjvh2Fhn6nH35derwcABAUFFbj+8f4NDAyEm5ub2boqVaoAQKHTLjxN/xdFcb9PUhyzyPrx6kIZ6XQ6BAYG4vTp08V63aO/eJ/E3t6+wPVCiKfeh8FgMHvs4uKCffv2Yffu3fjhhx/w008/4csvv0SrVq3wyy+/FBpDcZXkveTRarV49dVXsXr1aly6dAmTJ08udNsZM2YgKioKffr0wbRp0+Dt7Q07OzsMGzasyBU74GH/FMfx48dNfwBOnTpl9qtZbsWNNU9AQAC6du2K1157DTVq1MCmTZuwatUqODg4IDk5Gd9//z0yMzNRuXLlfK/dsGEDpk+fXuTPdGGGDRuGDh06YOvWrfj5558RFRWF6Oho7Nq1C/Xq1TP9n61duxb+/v75Xv94YlGSz23evkaNGoV27doVuM3jyb0Un++8/c6ePbvQ6UTc3d2L3J4UCntfUrzfwjxN/8tBzvdI1oNJlsxefvllLFu2DAcPHjS7jL0gwcHBMBqNiImJMf16AoDbt28jMTERwcHBksXl5eVV4KX4j/9aAwA7Ozu0bt0arVu3xscff4wZM2ZgwoQJ2L17t9n8R4++DwA4f/58vuf+/vtvlC1bNt+vV6l0794dn3/+Oezs7NC1a9dCt9u8eTNatmyJzz77zGx9YmIiypYta3pc0uTgUWlpaejduzeqV6+Oxo0bY9asWejcuTMaNGjwVO0FBwfjr7/+gtFoNPv1nTdZqJSfF+DhqZPatWsjJiYGd+/ehb+/P7755htkZmZi8eLFZv0GPPz//+9//4vff/8dTZs2LfH+w8LCMHLkSIwcORIxMTGoW7cu5syZg3Xr1pnm2PL19S3wM/k0Cvu/Dw0NBfCwP6TaV178p0+fLjRByNtGp9M91X7DwsJw+PBh5OTkFDqnXXBwMH799VekpKSYVbPk+kzduHEDaWlpZseDCxcuAEC+ea3yFKf/i/P9Vfr7RLaBpwtlNmbMGLi5uaFfv364fft2vudjY2Mxf/58AA9PdwHAvHnzzLb5+OOPAQDt27eXLK6wsDAkJSXhr7/+Mq27efMmtmzZYrbd/fv3870271d0VlZWgW0HBASgbt26WL16tVkid/r0afzyyy+m9ymHli1bYtq0aVi0aFGBFY089vb2+X5xfvXVV/nGcuQd/AtKSItr7NixiIuLw+rVq/Hxxx+jYsWKiIyMLLQf/81LL72EW7du4csvvzSty83NxcKFC+Hu7o4WLVo8VbsxMTGIi4vLtz4xMREHDx6El5eX6VTbunXrEBoaioEDB+L11183W0aNGgV3d/cSnzJMT0/PN5lsWFgYPDw8TH3Xrl076HQ6zJgxAzk5OfnayJsvrjhcXV0B5P+/9/X1RUREBJYuXYqbN29Ksq+2bdvCw8MD0dHR+d5r3ue0fv36CAsLw0cffYTU1NRi7/e1117D3bt3sWjRonzP5e3jpZdegsFgyLfN3LlzodFo8OKLLxbrff2b3Nxcs3GJ2dnZWLp0KXx8fFC/fv0CX1Oc/i/O91eu7xPZNlayZBYWFoYNGzbgjTfeQLVq1cxmfD9w4AC++uor0+1E6tSpg8jISCxbtgyJiYlo0aIFjhw5gtWrV6NTp05o2bKlZHF17doVY8eORefOnTFkyBCkp6dj8eLFqFKlitnA76lTp2Lfvn1o3749goODkZCQgE8//RTly5d/YnVi9uzZePHFF9GoUSP07dsXGRkZWLhwIfR6/RNP45WUnZ0d/vvf//7rdi+//DKmTp2K3r17o3Hjxjh16hTWr19v+pWcJywsDJ6enliyZAk8PDzg5uaGhg0bFmt8E/BwxvZPP/0UkyZNwjPPPAMAWLlyJSIiIhAVFYVZs2YVqz3g4WDqpUuXolevXvjjjz9QsWJFbN68Gb///jvmzZtX5AsuHnfy5El0794dL774Ipo1awZvb29cv34dq1evxo0bNzBv3jzY29vjxo0b2L17d75B0nm0Wi3atWuHr776CgsWLHjqOwJcuHABrVu3RpcuXVC9enU4ODhgy5YtuH37tqlaqdPpsHjxYrz11lt45pln0LVrV/j4+CAuLg4//PADmjRpUmBy8SQuLi6oXr06vvzyS1SpUgXe3t6oWbMmatasiU8++QRNmzZFrVq10L9/f4SGhuL27ds4ePAgrl27hpMnTxZrXzqdDnPnzkW/fv3QoEEDdO/eHV5eXjh58iTS09OxevVq2NnZYcWKFXjxxRdRo0YN9O7dG+XKlcP169exe/du6HQ6fP/994Xuo2fPnlizZg1GjBiBI0eOoFmzZkhLS8Ovv/6Kd999Fx07dkSHDh3QsmVLTJgwAVeuXEGdOnXwyy+/4Ntvv8WwYcMkn5U/MDAQH374Ia5cuYIqVargyy+/xIkTJ7Bs2bInfl6K2v9169aFvb09PvzwQyQlJUGr1aJVq1YFjoWU6/tENk6lqxptzoULF0T//v1FxYoVhZOTk/Dw8BBNmjQRCxcuNLsMOScnR0yZMkWEhIQIR0dHERQU9MTJSB/3+GXJhU3hIMTDSUZr1qwpnJycRHh4uFi3bl2+KRx27twpOnbsKAIDA4WTk5MIDAwU3bp1ExcuXMi3j8cvyf/1119FkyZNhIuLi9DpdKJDhw6FTkb6+BQReZe+Pz6B4eMencKhMIVN4TBy5EgREBAgXFxcRJMmTcTBgwcLnHrh22+/FdWrVxcODg4FTkZakEfbSU5OFsHBweKZZ57JN+/U8OHDhZ2dnTh48OAT30Nh/9+3b98WvXv3FmXLlhVOTk6iVq1a+f4fnvQZKMjt27fFzJkzRYsWLURAQIBwcHAQXl5eolWrVmLz5s2m7ebMmSMAiJ07dxba1qpVqwQAs0kiizuFw927d8WgQYNE1apVhZubm9Dr9aJhw4Zi06ZN+bbdvXu3aNeundDr9cLZ2VmEhYWJXr16iWPHjpm2KewzU9BEvAcOHBD169cXTk5O+aZziI2NFT179hT+/v7C0dFRlCtXTrz88stmfZT3OT569Gi+OFHA1ALfffedaNy4sek785///Eds3LjRbJvjx4+LV199VZQpU0ZotVoRHBwsunTp8sT/hzzp6eliwoQJpuOLv7+/eP31101zvwnxcDqM4cOHi8DAQOHo6CgqV678xMlIH1XYZy3v/X711VemdQVNRhocHCwWLVpUYJuPf16K0v9CCLF8+XIRGhoq7O3tizQZaUm+T49/Rog0QnCUHhERKSsiIgJ3794t9oVBRKUJx2QRERERyYBJFhEREZEMmGQRERERyYBJFhERKW7Pnj0cj0Wq2rdvHzp06IDAwEBoNBps3brV7HkhBCZOnIiAgAC4uLjg+eefN915oaiYZBEREZHNSUtLQ506dfDJJ58U+PysWbOwYMECLFmyBIcPH4abmxvatWuXby67J+HVhURERGTTNBoNtmzZgk6dOgF4WMUKDAzEyJEjMWrUKABAUlIS/Pz8sGrVqifeUeRRpXoyUqPRiBs3bsDDw0PS258QERFZIyEEUlJSEBgYmO9m2ErIzMxEdna2LG0LIfLlAlqtFlqttthtXb58Gbdu3TK7dZNer0fDhg1x8OBB20iybty4ke9u70RERPRk8fHxKF++vKL7zMzMREiwO24lGGRp393dPd8tpyZNmvRUdxm5desWAMDPz89svZ+fn+m5oijVSVbebQ5e+64LHN2e7pYdRJZucdBBtUOwOa93fFXtEIhkkWvIwt4LC1W5TVB2djZuJRhw9Y+K0HlIW0VLTjEiuP4VxMfHQ6fTmdY/TRVLSqU6ycorCzq6OcLJ3UnlaIjkIfXBiP6dg726B2Yiuak5xMbdQwN3D2n3b8TD9nQ6nVmS9bT8/f0BALdv30ZAQIBp/e3bt1G3bt0it8OjNxERESnGIIyyLFIKCQmBv78/du7caVqXnJyMw4cPo1GjRkVup1RXsoiIiIieRmpqKi5evGh6fPnyZZw4cQLe3t6oUKEChg0bhg8++ACVK1dGSEgIoqKiEBgYaLoCsSiYZBEREZFijBAwQtrZo56mvWPHjqFly5amxyNGjAAAREZGYtWqVRgzZgzS0tLw9ttvIzExEU2bNsVPP/0EZ2fnIu+DSRYRERHZnIiICDxpqlCNRoOpU6di6tSpT70PJllERESkGCOMkHYEFWRoURoc+E5EREQkA1ayiIiISDEGIWCQ+I5+UrcnFVayiIiIiGTAShYREREpxlKuLlQCkywiIiJSjBECBhtJsni6kIiIiEgGrGQRERGRYmzpdCErWUREREQyYCWLiIiIFMMpHIiIiIioRFjJIiIiIsUY/1mkbtMSsZJFREREJANWsoiIiEgxBhnmyZK6PakwySIiIiLFGMTDReo2LRFPFxIRERHJgJUsIiIiUgwHvhMRERFRibCSRURERIoxQgMDNJK3aYlYySIiIiKSAStZREREpBijeLhI3aYlYiWLiIiISAasZBEREZFiDDKMyZK6PakwySIiIiLF2FKSxdOFRERERDJgJYuIiIgUYxQaGIXEUzhI3J5UWMkiIiIikgErWURERKQYjskiIiIiohJhJYuIiIgUY4AdDBLXeAyStiYdVrKIiIiIZMBKFhERESlGyHB1obDQqwuZZBEREZFiOPCdiIiIiEqElSwFCYNAyopsZPyUA8N9AfuyGri2d4R7bydoNJaZhZdm7G/5nTrkhq8+9UXMKVfcv+2ISZ9dRuMXk0zPCwGsme2PnzaUQWqyPao/m4YhM+NRLjRbxaitx0svX0T7DrHw80sDAFy9qsfGddVx7GiAypFZL/Z5yRmEHQxC4oHvQtLmJMMkS0Gpa7OR/k0OPCc6wyHEDjl/G5D4QSY0bhq4v+GkdnhWh/0tv8x0O4TWyEC7bvcxtW9Ivuc3feKLbz/3wah5V+FfIRurZwXg/e5hWL7nbzg5W+hRsRS5e9cVKz+rjRvX3aEB0LrtFURN+R3vvdMGcVf1aodnldjnVBxMshSUfcoA5+YOcG7ysNsdAu2Q8Usucs5a6sWnpRv7W34NWqWgQauUAp8TAti6wgfdht5C4xeSAQBjFlzFG3Vq4sBPekR0SlQwUut05FCg2eM1K2uh/cuxqFrtHv/gy4R9XnJGaGCUeLSSEZb5o031MVk//fQTmjZtCk9PT5QpUwYvv/wyYmNj1Q5LFk617JF1NBe5cUYAQE6MAdknDdA2Yq4rB/a3um7FOeF+giOeaZZqWuemM6JqvXSc+8NNxcisk52dEc0j4uDsnItzZ8uoHY5NYJ/Tv1H9r01aWhpGjBiB2rVrIzU1FRMnTkTnzp1x4sQJ2NmZ54BZWVnIysoyPU5OTlY63BJx7+kEkQYkvJH2ML01Ah4DneD6gqPaoVkl9re67ic8PLx4+uSYrff0yTE9RyVXsWIi5izYBScnAzIyHDBtShPEx7GiIif2ecnY0tWFqh/pXnvtNbPHn3/+OXx8fHD27FnUrFnT7Lno6GhMmTJFyfAklbkzF+k/58Br6j9jhGKMSJqbCfuydnBtzz/8UmN/ky24ds0Dgwe2gZtbDpo2u4aRo49gzMgI/tGXEfucikr104UxMTHo1q0bQkNDodPpULFiRQBAXFxcvm3Hjx+PpKQk0xIfH69wtCWTtDALHj2d4NLGEY6V7OH6oiPcuzohdQ2vtJID+1td3r65AIDEO+YJbeIdR9NzVHK5ufa4ecMDF2O8serz2rh0SY+OnWPUDsuqsc9LJu/qQqkXS6R6JatDhw4IDg7G8uXLERgYCKPRiJo1ayI7O/8fQq1WC61Wq0KU0hCZAvkqmvaAMFrmgL3Sjv2tLv8K2fD2zcHx/e4Iq5kBAEhLscPfx13xcs+7Kkdnvew0gKOTUe0wbAr7vHgeDnyX9vSe1O1JRdUk6969ezh//jyWL1+OZs2aAQD279+vZkiycm7qgJRV2bD3t3t4+uqCAWkbc+D6Mk9dyYH9Lb+MNDvcuPy/Hz634p0Qe9oFHp658C2fg0797mDjfD+UC8kyTeFQxi8HjV9IekKrVFS9+vyFY0cDkJDgCleXHES0ikOtOgmIGt9c7dCsFvucikPVJMvLywtlypTBsmXLEBAQgLi4OIwbN07NkGSlH+mMlGVZSJqdCcODfybH7OQIj76cs0kO7G/5XTjpijGvVzI9Xjq5HACgTZf7GDUvDl0GJSAz3Q7zxwQhNdkeNRqkYfr6S5wjSyJ6zyyMHHMY3t6ZSEtzxOXLekSNb47jf/qrHZrVYp+XnBF2MNjIFA6qJll2dnb44osvMGTIENSsWRPh4eFYsGABIiIi1AxLNnZuGuiHO0M/XO1IbAP7W351Gqfi5xsnCn1eowEix9xC5JhbygVlQ+Z/3EDtEGwO+5yKQ/UxWc8//zzOnj1rtk4Iy8xIiYiIqGTkua2OZeYNljkcn4iIiKiUY5JFREREijHCTpaluFJSUjBs2DAEBwfDxcUFjRs3xtGjRyV9r0yyiIiIyOb069cPO3bswNq1a3Hq1Cm0bdsWzz//PK5fvy7ZPphkERERkWIMQiPLAjy83d6jy6O34ntURkYGvv76a8yaNQvNmzdHpUqVMHnyZFSqVAmLFy+W7L0yySIiIiLFGP6ZwkHqBQCCgoKg1+tNS3R0dIEx5ObmwmAwwNnZ2Wy9i4uLpPN1qn51IREREZEU4uPjodPpTI8Lu0uMh4cHGjVqhGnTpqFatWrw8/PDxo0bcfDgQVSqVKnA1zwNVrKIiIhIMUZhJ8sCADqdzmx50q341q5dCyEEypUrB61WiwULFqBbt26ws5MuNWKSRURERDYnLCwMe/fuRWpqKuLj43HkyBHk5OQgNDRUsn3wdCEREREp5tExVNK1+fSTkbq5ucHNzQ0PHjzAzz//jFmzZkkWF5MsIiIisjk///wzhBAIDw/HxYsXMXr0aFStWhW9e/eWbB9MsoiIiEgxRsA05YKUbRZXUlISxo8fj2vXrsHb2xuvvfYapk+fDkdHR8niYpJFRERENqdLly7o0qWLrPtgkkVERESKedrb4Pxbm5aISRYREREpxiDsYBASD3yXuD2pWGZURERERKUcK1lERESkGCM0MELqge/SticVVrKIiIiIZMBKFhERESmGY7KIiIiIqERYySIiIiLFyHNbHcusGVlmVERERESlHCtZREREpBij0MAo9W11JG5PKqxkEREREcmAlSwiIiJSjFGGMVm8rQ4RERHZPKOwg1HiKRekbk8qlhkVERERUSnHShYREREpxgANDBLfBkfq9qTCShYRERGRDFjJIiIiIsVwTBYRERERlQgrWURERKQYA6QfQ2WQtDXpsJJFREREJANWsoiIiEgxtjQmi0kWERERKcYg7GCQOCmSuj2pWGZURERERKUcK1lERESkGAENjBIPfBecjJSIiIjIdrCSRURERIqxpTFZVpFkLQ46CJ2HZXawtWk2aIDaIdicsOY11A7B5jhPTVE7BJtyptF6tUOwGckpRnhVUTsK22EVSRYRERGVDkahgVFIO4ZK6vakwvIPERERkQxYySIiIiLFGGAHg8Q1HqnbkwqTLCIiIlIMTxcSERERUYmwkkVERESKMcIORolrPFK3JxXLjIqIiIiolGMli4iIiBRjEBoYJB5DJXV7UmEli4iIiEgGrGQRERGRYnh1IRERERGVCCtZREREpBgh7GCU+IbOgjeIJiIiIltngAYGSDzwXeL2pGKZqR8RERFRKcdKFhERESnGKKQfqG4UkjYnGVayiIiIiGTAShYREREpxijDwHep25OKZUZFREREVMqxkkVERESKMUIDo8RXA0rdnlRYySIiIiKbYjAYEBUVhZCQELi4uCAsLAzTpk2DENKOoGcli4iIiBRjCTeI/vDDD7F48WKsXr0aNWrUwLFjx9C7d2/o9XoMGTJEsriYZBEREZFiLGHg+4EDB9CxY0e0b98eAFCxYkVs3LgRR44ckTQuni4kIiIiq5CcnGy2ZGVlFbhd48aNsXPnTly4cAEAcPLkSezfvx8vvviipPGwkkVERESKMUIj/WSk/wx8DwoKMls/adIkTJ48Od/248aNQ3JyMqpWrQp7e3sYDAZMnz4dPXr0kDQuJllERERkFeLj46HT6UyPtVptgdtt2rQJ69evx4YNG1CjRg2cOHECw4YNQ2BgICIjIyWLh0kWERERKUbIMIWD+Kc9nU5nlmQVZvTo0Rg3bhy6du0KAKhVqxauXr2K6OhoSZMsjskiIiIim5Keng47O/MUyN7eHkajUdL9sJJFREREijEKGcZkFbO9Dh06YPr06ahQoQJq1KiB48eP4+OPP0afPn0kjYtJFhEREdmUhQsXIioqCu+++y4SEhIQGBiIAQMGYOLEiZLuh0kWERERKcYS5sny8PDAvHnzMG/ePEnjeByTLCIiIlKMJZwuVAoHvhMRERHJgJUsIiIiUoxRhikcpG5PKqxkEREREcmAlSwiIiJSDMdkEREREVGJsJJFREREimEli4iIiIhKhJUsIiIiUowtVbKYZBEREZFibCnJ4ulCIiIiIhmoWsmKiIhA3bp1Zb93kFpOHXLDV5/6IuaUK+7fdsSkzy6j8YtJpueFANbM9sdPG8ogNdke1Z9Nw5CZ8SgXmq1i1NarR5sTGNjpCDbtqomFXzdWOxyrZZ+YjbLb4uB6LhGaHANyyjojoWsYsiq4qx2a1fEfeAEOd3LyrU99wQuJ/QNViMj68DguPQHpJw8VkrYmHVayZJSZbofQGhkYPONagc9v+sQX337ug/dmxmP+tgtwdjXi/e5hyM60zLJnaVa1QgJeaXoOF695qx2KVbNLz0X5Bach7DW48XZVxI2tg7uvBMPgypEJckj4MBQ3VlQxLXcmBgMAMhrpVY7MevA4TiXBI5+MGrRKQYNWKQU+JwSwdYUPug29hcYvJAMAxiy4ijfq1MSBn/SI6JSoYKTWzUWbg4m9dmPWhmaIfOG42uFYNa+dN5DrqUVCtzDTutwyzipGZN2MevNDuPOWu8j1d0JWDVeVIrI+PI5Lj2OyFJSbm4vBgwdDr9ejbNmyiIqKghCWWviTzq04J9xPcMQzzVJN69x0RlStl45zf7ipGJn1Gd5lPw6eCcIf58urHYrVczvzAFlBbvBfdQEVo44h6KO/oDt4W+2wbEOOEa77kpDWyhPQWOYfHGvD4zj9G9WTrNWrV8PBwQFHjhzB/Pnz8fHHH2PFihUFbpuVlYXk5GSzpbS6n/DwF6inj/l4Ck+fHNNzVHKt619ElaC7WPrtf9QOxSY43MuE7sBtZPs448aAakhq7IeyW67A48gdtUOzei5HUmCXZkBaS0+1Q7EZPI4/nbxKltSLJVL9UxAUFIS5c+dCo9EgPDwcp06dwty5c9G/f/9820ZHR2PKlCkqREmlka9nKoa8fhAjFr6E7FzVP+o2QSOAzCA33G9fAQCQXd4NTrcyoD9wGyn/8VE5OuvmtvMBMuu5w+jtqHYoRPQP1StZzz33HDSPlLYbNWqEmJgYGAyGfNuOHz8eSUlJpiU+Pl7JUCXl7ZsLAEi8Y35ATLzjaHqOSia8wl146zKwYtw32L1gOXYvWI56VW7i9YjT2L1gOew0RrVDtDq5Okdk+7mYrcv2c4ZDYpZKEdkG+4RsaE+lIe15L7VDsSk8jj8dVrIslFarhVarVTsMSfhXyIa3bw6O73dHWM0MAEBaih3+Pu6Kl3veVTk663DsfCB6fvC62brxb+1F3G091v9SF0ah+m8Mq5MZ4gGnhEyzdU4Jmcjxso7vraVy250Io84BmfU91A7FpvA4/nRsaeC76knW4cOHzR4fOnQIlStXhr29vUoRSScjzQ43Lv/vj8uteCfEnnaBh2cufMvnoFO/O9g43w/lQrLgXyEbq2cFoIxfDhq/kPSEVqmoMrKccPmm+ZQNmVkOSEp1zreepJHYIgDl55+B147rSK1bBtq4VOgOJSChS6jaoVkvo4DrrkSkRXgC9pb5h6Y043GcSkL1JCsuLg4jRozAgAED8Oeff2LhwoWYM2eO2mFJ4sJJV4x5vZLp8dLJ5QAAbbrcx6h5cegyKAGZ6XaYPyYIqcn2qNEgDdPXX4KTs/VfXUnWKauCO272qYIyP8TB65dryPXW4m6nYKTWL6t2aFZL+1caHO7mIL21p9qhWCUex6UnhAZC4sqT1O1JRSNUnC8hIiICNWrUgNFoxIYNG2Bvb4933nkHH3zwgdk4rcIkJydDr9fjwYVQ6Dx46kcJzQYNUDsEm3OjuWUePKyZc4WC50UieZxptF7tEGxGcooRXlUuISkpCTqdTtl9//M3u8m3g+HgJu0Qgty0LPzecZEq7+tJVK1k7dmzx/TvxYsXqxcIERERKcIIjeS31ZG6Pamw/ENEREQkA9XHZBEREZHtsKWrC1nJIiIiIpIBK1lERESkGFu6upCVLCIiIiIZsJJFREREirGlMVlMsoiIiEgxPF1IRERERCXCShYREREpRshwupCVLCIiIiIbwkoWERERKUYAkPquyZZ6O25WsoiIiIhkwEoWERERKcYIDTS8QTQRERERPS1WsoiIiEgxtjRPFpMsIiIiUoxRaKCxkRnfebqQiIiISAasZBEREZFihJBhCgcLncOBlSwiIiIiGbCSRURERIqxpYHvrGQRERERyYCVLCIiIlIMK1lEREREVCKsZBEREZFiOE8WERERkQzypnCQeimOihUrQqPR5FsGDRok6XtlJYuIiIhsytGjR2EwGEyPT58+jTZt2uD//u//JN0PkywiIiJSzMPKk9QD34u3vY+Pj9njmTNnIiwsDC1atJAwKiZZREREZCWSk5PNHmu1Wmi12ie+Jjs7G+vWrcOIESOg0Uib/HFMFhERESkmbwoHqRcACAoKgl6vNy3R0dH/Gs/WrVuRmJiIXr16Sf5eWckiIiIiqxAfHw+dTmd6/G9VLAD47LPP8OKLLyIwMFDyeJhkERERkWLEP4vUbQKATqczS7L+zdWrV/Hrr7/im2++kTiih3i6kIiIiGzSypUr4evri/bt28vSPitZREREpBhLua2O0WjEypUrERkZCQcHedIhJllERESkHDnPFxbDr7/+iri4OPTp00fiYP6HSRYRERHZnLZt20IUd4KtYmKSRURERMqR4XQheO9CIiIiItvBShYREREp5mlu6FyUNi0RK1lEREREMrCKStY78Y3g5O6kdhhEsnCP428hxcXp1Y7AptTZ/67aIdgMQ1YmgPdVjcFSpnBQAo/eRERERDKwikoWERERlRJCI/3VgBZayWKSRURERIrhwHciIiIiKhFWsoiIiEg5FnJbHSWwkkVEREQkA1ayiIiISDGcwoGIiIiISoSVLCIiIlKWhY6hkhorWUREREQyYCWLiIiIFGNLY7KYZBEREZFyOIUDEREREZUEK1lERESkIM0/i9RtWp4iJVnfffddkRt85ZVXnjoYIiIiImtRpCSrU6dORWpMo9HAYDCUJB4iIiKyZjY0JqtISZbRaJQ7DiIiIiKrUqKB75mZmVLFQURERLZAyLRYoGInWQaDAdOmTUO5cuXg7u6OS5cuAQCioqLw2WefSR4gERERUWlU7CRr+vTpWLVqFWbNmgUnJyfT+po1a2LFihWSBkdERERWRmjkWSxQsZOsNWvWYNmyZejRowfs7e1N6+vUqYO///5b0uCIiIjIugghz2KJip1kXb9+HZUqVcq33mg0IicnR5KgiIiIiEq7YidZ1atXx2+//ZZv/ebNm1GvXj1JgiIiIiIrZUMD34s94/vEiRMRGRmJ69evw2g04ptvvsH58+exZs0abNu2TY4YiYiIiEqdYleyOnbsiO+//x6//vor3NzcMHHiRJw7dw7ff/892rRpI0eMREREZC1saOD7U927sFmzZtixY4fUsRARERFZjae+QfSxY8dw7tw5AA/HadWvX1+yoIiIiMg6acTDReo2LVGxk6xr166hW7du+P333+Hp6QkASExMROPGjfHFF1+gfPnyUsdIREREVOoUe0xWv379kJOTg3PnzuH+/fu4f/8+zp07B6PRiH79+skRIxEREVkLXl1YuL179+LAgQMIDw83rQsPD8fChQvRrFkzSYMjIiIiKyPHQHULHfhe7EpWUFBQgZOOGgwGBAYGShIUERERUWlX7CRr9uzZeO+993Ds2DHTumPHjmHo0KH46KOPJA2OiIiIrAxPF5rz8vKCRvO/UlxaWhoaNmwIB4eHL8/NzYWDgwP69OmDTp06yRIoERERUWlSpCRr3rx5ModBRERENkGOylNprmRFRkbKHQcRERGRVXnqyUgBIDMzE9nZ2WbrdDpdiQIiIiIiK2ZDlaxiD3xPS0vD4MGD4evrCzc3N3h5eZktRERERPQUSdaYMWOwa9cuLF68GFqtFitWrMCUKVMQGBiINWvWyBEjERERWQveILpw33//PdasWYOIiAj07t0bzZo1Q6VKlRAcHIz169ejR48ecsRJREREVKoUu5J1//59hIaGAng4/ur+/fsAgKZNm2Lfvn3SRkdERERWJe8G0VIvlqjYlazQ0FBcvnwZFSpUQNWqVbFp0yb85z//wffff2+6YTQVTBgEUlZkI+OnHBjuC9iX1cC1vSPcezuZzUNG8ujR5gQGdjqCTbtqYuHXjdUOxyoNbHwU7zQ5Zrbu8j1PdPq8m0oRWTf2t/LY5xKwoYHvxU6yevfujZMnT6JFixYYN24cOnTogEWLFiEnJwcff/yxHDFajdS12Uj/JgeeE53hEGKHnL8NSPwgExo3DdzfcFI7PKtWtUICXml6DheveasditW7eMcLb3/1iumxwcgfEHJifyuPfU5FVewka/jw4aZ/P//88/j777/xxx9/oFKlSqhdu7akwVmb7FMGODd3gHOTh93uEGiHjF9ykXPWoHJk1s1Fm4OJvXZj1oZmiHzhuNrhWL1cYYd7aa5qh2Ez2N/KY59bh+vXr2Ps2LHYvn070tPTUalSJaxcuRLPPvusZPso0TxZABAcHIzg4GApYrF6TrXskb41B7lxRjhUsENOjAHZJw3QDdWqHZpVG95lPw6eCcIf58szyVJAsGcSdryzGtm59jh5wx8L9jXErRQPtcOyWuxv5bHPS78HDx6gSZMmaNmyJbZv3w4fHx/ExMRIPhVVkZKsBQsWFLnBIUOGFDsIo9GIjz76CMuWLUN8fDz8/PwwYMAATJgwodhtWTL3nk4QaUDCG2kPLzkwAh4DneD6gqPaoVmt1vUvokrQXbw9q7PaodiEUzd9EbW9Fa488ISPWxoGND6Gld224rWVbyA9h6fEpcb+Vh77vOQ0kH6genFP2H744YcICgrCypUrTetCQkKkDQpFTLLmzp1bpMY0Gs1TJVnjx4/H8uXLMXfuXDRt2hQ3b97E33//nW+7rKwsZGVlmR4nJycXe19qytyZi/Sfc+A19Z8xWTFGJM3NhH1ZO7i2Z6IlNV/PVAx5/SBGLHwJ2bklLtpSEfx++X9V7Zg7ZXDqph+2D1iHdlVjseVUNRUjs07sb+Wxzy3b43mBVquFVpv/bNF3332Hdu3a4f/+7/+wd+9elCtXDu+++y769+8vaTxF+stz+fJlSXf6qJSUFMyfPx+LFi0y3SMxLCwMTZs2zbdtdHQ0pkyZIlsscktamAWPnk5wafMwoXKsZA/DTSNS12QzyZJBeIW78NZlYMW4b0zrHOwF6lS6iVdbnEHroX1hFMWexYSKISVLi6v39QjyTFI7FJvA/lYe+/wpyDF56D/tBQUFma2eNGkSJk+enG/zS5cuYfHixRgxYgTef/99HD16FEOGDIGTk5Ok92tW/ef9uXPnkJWVhdatW//rtuPHj8eIESNMj5OTk/N1qCUTmSJ/TdMeEEYLvfa0lDt2PhA9P3jdbN34t/Yi7rYe63+pywRLAS6OOQjyTMYPZzlIWAnsb+Wxzy1LfHy82T2UC6piAQ+HKT377LOYMWMGAKBevXo4ffo0lixZYl1JlouLS5G3LazsV1o4N3VAyqps2PvbPTxdeMGAtI05cH2ZVSw5ZGQ54fJN8ykbMrMckJTqnG89SWNExAHsvVgRN5Pd4eOejneaHIVBaLD9XGW1Q7NK7G/lsc8lIOM8WTqdzizJKkxAQACqV69utq5atWr4+uuvJQ1L9SSrcuXKcHFxwc6dO9GvXz+1w5GVfqQzUpZlIWl2JgwP/pmMtJMjPPpysCRZBz/3NMzssAOezpl4kOGC49cC8Nb6V/Ego+g/pqjo2N/KY59LwAImI23SpAnOnz9vtu7ChQuSz5agepLl7OyMsWPHYsyYMXByckKTJk1w584dnDlzBn379lU7PEnZuWmgH+4M/fB/35bkMWR+B7VDsGpjt7VROwSbwv5WHvvcOgwfPhyNGzfGjBkz0KVLFxw5cgTLli3DsmXLJN2P6kkWAERFRcHBwQETJ07EjRs3EBAQgIEDB6odFhEREUlMjnsNFre9Bg0aYMuWLRg/fjymTp2KkJAQzJs3Dz169JA0rqdKsn777TcsXboUsbGx2Lx5M8qVK4e1a9ciJCSkwKsC/42dnR0mTJhgdfNiERERkWV6+eWX8fLLL8u6j2JfXvX111+jXbt2cHFxwfHjx03zViUlJZlG6RMREREVSMi0WKBiJ1kffPABlixZguXLl8PR8X9XxTVp0gR//vmnpMERERERlVbFPl14/vx5NG/ePN96vV6PxMREKWIiIiIia2UBVxcqpdiVLH9/f1y8eDHf+v379yM0NFSSoIiIiIhKu2InWf3798fQoUNx+PBhaDQa3LhxA+vXr8eoUaPwzjvvyBEjERERWYm8qwulXixRsU8Xjhs3DkajEa1bt0Z6ejqaN28OrVaLUaNG4b333pMjRiIiIrIWMt670NIUO8nSaDSYMGECRo8ejYsXLyI1NRXVq1eHu7u7HPERERERlUpPPRmpk5NTvvv+EBERET2RDQ18L3aS1bJlS2g0hZfldu3aVaKAiIiIiKxBsZOsunXrmj3OycnBiRMncPr0aURGRkoVFxEREVkhS7itjlKKnWTNnTu3wPWTJ09GampqiQMiIiIisgbFnsKhMG+++SY+//xzqZojIiIia8Tb6hTfwYMH4ezsLFVzRERERKVasU8Xvvrqq2aPhRC4efMmjh07hqioKMkCIyIiIiskx+ShFlrJKnaSpdfrzR7b2dkhPDwcU6dORdu2bSULjIiIiKwQp3AomMFgQO/evVGrVi14eXnJFRMRERFRqVesMVn29vZo27YtEhMTZQqHiIiIrBoHvheuZs2auHTpkhyxEBEREVmNYidZH3zwAUaNGoVt27bh5s2bSE5ONluIiIiICpM3GanUiyUq8pisqVOnYuTIkXjppZcAAK+88orZ7XWEENBoNDAYDNJHSURERFTKFDnJmjJlCgYOHIjdu3fLGQ8RERGRVShykiXEw1pcixYtZAuGiIiIyFoUawqHR08PEhERERUb58kqWJUqVf410bp//36JAiIiIiLrJcdA9VI/8B14OC7r8RnfiYiIiCi/YiVZXbt2ha+vr1yxEBERkS2w0MqT1Io8TxbHYxEREREVXbGvLiQiIiJ6ahz4np/RaJQzDiIiIiKrUqwxWUREREQlYUtXFxb73oVERERE9O9YySIiIiLlcEwWERERkfR4upCIiIiISoSVLCIiIlKODZ0uZCWLiIiISAasZBEREZFyWMkiIiIiopJgJYuIiIgUY0tXF1pFkvXHzSDYu2rVDsMmeKsdgA1KrcBbWimt0vBDaodgU+xrhKsdgs3INWThnNpB2BCrSLKIiIiolLChMVlMsoiIiEg5NpRkceA7ERERkQxYySIiIiLF2NLAd1ayiIiIiGTAShYREREph2OyiIiIiKgkmGQRERGRYvLGZEm9FMfkyZOh0WjMlqpVq0r+Xnm6kIiIiGxOjRo18Ouvv5oeOzhInxIxySIiIiLlyDgmKzk52Wy1VquFVlvwHWEcHBzg7+8vcSDmeLqQiIiIlCNkWgAEBQVBr9eblujo6ELDiImJQWBgIEJDQ9GjRw/ExcVJ/lZZySIiIiKrEB8fD51OZ3pcWBWrYcOGWLVqFcLDw3Hz5k1MmTIFzZo1w+nTp+Hh4SFZPEyyiIiISDGafxap2wQAnU5nlmQV5sUXXzT9u3bt2mjYsCGCg4OxadMm9O3bV7K4eLqQiIiIbJqnpyeqVKmCixcvStoukywiIiJSjoxjsp5WamoqYmNjERAQULKGHsMki4iIiGzKqFGjsHfvXly5cgUHDhxA586dYW9vj27dukm6H47JIiIiIsVYwg2ir127hm7duuHevXvw8fFB06ZNcejQIfj4+EgaF5MsIiIisilffPGFIvthkkVERETKsaEbRDPJIiIiImVZaFIkNQ58JyIiIpIBK1lERESkGEsY+K4UVrKIiIiIZMBKFhERESnHhga+s5JFREREJANWsoiIiEgxHJNFRERERCXCShYREREph2OyiIiIiKgkWMkiIiIixdjSmCwmWURERKQcni4kIiIiopJgJYuIiIiUw0oWEREREZUEK1lERESkGFsa+M5KFhEREZEMWMkiIiIi5XBMFhERERGVBCtZREREpBiNENAIaUtPUrcnFSZZREREpBwbOl1ocUlWREQE6tati3nz5qkdiuT8B16Aw52cfOtTX/BCYv9AFSKyLT3anMDATkewaVdNLPy6sdrhWC37xGyU3RYH13OJ0OQYkFPWGQldw5BVwV3t0KzOG4Nvo8lLSQiqlIXsTDucPeaKz6YH4Fqss9qhWa2XXr6I9h1i4eeXBgC4elWPjeuq49jRAJUjI0tkcUmWNUv4MBQw/i/ddozLgs/Uq8hopFcxKttQtUICXml6DheveasdilWzS89F+QWnkVFZjxtvV4XB3QGOdzJhcOWhRg61G6Xh+1VlceGEK+wdBHqNu4kZGy+hf4twZGXYqx2eVbp71xUrP6uNG9fdoQHQuu0VRE35He+90wZxV3ksLwpbmsKBRz4FGfXm3e285S5y/Z2QVcNVpYhsg4s2BxN77casDc0Q+cJxtcOxal47byDXU4uEbmGmdbllWFWRy4QeoWaP5wyrgE2nz6By7QycPszKoRyOHDI/67BmZS20fzkWVavdY5JF+ah6dWFaWhp69uwJd3d3BAQEYM6cOWqGo6wcI1z3JSGtlSeg0agdjVUb3mU/Dp4Jwh/ny6sditVzO/MAWUFu8F91ARWjjiHoo7+gO3hb7bBshpvOAABISWQVSwl2dkY0j4iDs3Muzp0to3Y4pYeQabFAqlayRo8ejb179+Lbb7+Fr68v3n//ffz555+oW7dugdtnZWUhKyvL9Dg5OVmhSKXnciQFdmkGpLX0VDsUq9a6/kVUCbqLt2d1VjsUm+BwLxO6A5lIjAjA/efLwTkuFWW3XIGwt0PKf3zUDs+qaTQCA6dcx+kjrrh63kXtcKxaxYqJmLNgF5ycDMjIcMC0KU0QH8cqFuWnWpKVmpqKzz77DOvWrUPr1q0BAKtXr0b58oVXG6KjozFlyhSlQpSV284HyKznDqO3o9qhWC1fz1QMef0gRix8Cdm5PDOuBI0AMoPccL99BQBAdnk3ON3KgP7AbSZZMhs84zqCq2ZiZKdKaodi9a5d88DggW3g5paDps2uYeToIxgzMoKJVhFxTJYCYmNjkZ2djYYNG5rWeXt7Izw8vNDXjB8/HiNGjDA9Tk5ORlBQkKxxysE+IRvaU2m4N7r0xV6ahFe4C29dBlaM+8a0zsFeoE6lm3i1xRm0HtoXRsH5eKWUq3NEtp95FSXbzxnuf91TKSLbMGj6NTRsk4yRncNw96aT2uFYvdxce9y84QEAuBjjjcrh99GxcwwWzX9W5cjI0pSqn/darRZarVbtMErMbXcijDoHZNb3UDsUq3bsfCB6fvC62brxb+1F3G091v9SlwmWDDJDPOCUkGm2zikhEzlepf97a5kEBk2/jsYvJGH065VwO579rAY7DeDoZFQ7jNLDhubJUu2vTFhYGBwdHXH48GHTugcPHuDChQtqhaQMo4DrrkSkRXgC9hzwLqeMLCdcvulttmRmOSAp1RmXb3IqBzkktgiA89VUeO24Dsc7mXD/4y50hxKQ1NRf7dCs0uAZ19Hq1QeYOSgYGal28PLJgZdPDpyc+QdfLr36/IWate7A1y8NFSsmolefv1CrTgL27KygdmilRt7pQqkXS6RaJcvd3R19+/bF6NGjUaZMGfj6+mLChAmws7Pu6oL2rzQ43M1BemtPtUMhklxWBXfc7FMFZX6Ig9cv15DrrcXdTsFIrV9W7dCsUodeD0/DfvRNrNn6j4YFYccm/pCQg94zCyPHHIa3dybS0hxx+bIeUeOb4/if/CFB+al6unD27NlITU1Fhw4d4OHhgZEjRyIpKUnNkGSXVdcd176uoXYYNmvI/A5qh2D10mt4Ib2Gl9ph2IR2gXXUDsHmzP+4gdohlH42dLpQ1STL3d0da9euxdq1a03rRo8erWJERERERNIoVQPfiYiIqPSz1DFUUrPuAVBEREREKmEli4iIiJQjxMNF6jYtECtZRERERDJgJYuIiIgUw9vqEBEREcnBhqZw4OlCIiIiIhmwkkVERESK0RgfLlK3aYlYySIiIiKSAStZREREpByOySIiIiKikmAli4iIiBRjS1M4sJJFRERENm3mzJnQaDQYNmyYpO2ykkVERETKsbDb6hw9ehRLly5F7dq1JQzoIVayiIiISDF5pwulXp5GamoqevTogeXLl8PLy0vaNwomWURERGQlkpOTzZasrKwnbj9o0CC0b98ezz//vCzxMMkiIiIi5QiZFgBBQUHQ6/WmJTo6utAwvvjiC/z5559P3KakOCaLiIiIrEJ8fDx0Op3psVarLXS7oUOHYseOHXB2dpYtHiZZREREpBg5p3DQ6XRmSVZh/vjjDyQkJOCZZ54xrTMYDNi3bx8WLVqErKws2NvblzguJllERERkU1q3bo1Tp06ZrevduzeqVq2KsWPHSpJgAUyyiIiISEkWMIWDh4cHatasabbOzc0NZcqUybe+JDjwnYiIiEgGrGQRERGRYiz1tjp79uwpeSOPYZJFREREynlkygVJ27RAPF1IREREJANWsoiIiEgxlnq6UA6sZBERERHJgJUsIiIiUo5RPFykbtMCsZJFREREJANWsoiIiEg5vLqQiIiIiEqClSwiIiJSjAYyXF0obXOSYZJFREREyrGAexcqhacLiYiIiGTAShYREREphpOREhEREVGJsJJFREREyuEUDkRERERUEqxkERERkWI0QkAj8dWAUrcnFatIso78ZxN0HizKKSEsbqDaIRDJ7trXNdQOwaY47NerHYLNMGRlAufUjsJ2WEWSRURERKWE8Z9F6jYtEJMsIiIiUowtnS7kOTYiIiIiGbCSRURERMrhFA5EREREVBKsZBEREZFyeINoIiIiIioJVrKIiIhIMbxBNBERERGVCCtZREREpByOySIiIiKikmAli4iIiBSjMT5cpG7TEjHJIiIiIuXwdCERERERlQQrWURERKQc3laHiIiIiEqClSwiIiJSjEYIaCQeQyV1e1JhJYuIiIhIBqxkERERkXJ4dSERERERlQQrWURERKQcAUDqyUMts5DFJIuIiIiUw4HvRERERFQirGQRERGRcgRkGPgubXNSYSWLiIiISAasZBEREZFyOIUDEREREZUEK1lERESkHCMAjQxtWiBWsoiIiIhkwEoWERERKYbzZBERERHJIW/gu9RLMSxevBi1a9eGTqeDTqdDo0aNsH37dsnfKpMsIiIisinly5fHzJkz8ccff+DYsWNo1aoVOnbsiDNnzki6H54uJCIiIuVYwBQOHTp0MHs8ffp0LF68GIcOHUKNGjUkC4tJFhEREVmF5ORks8darRZarfaJrzEYDPjqq6+QlpaGRo0aSRoPTxcSERGRcmQckxUUFAS9Xm9aoqOjCw3j1KlTcHd3h1arxcCBA7FlyxZUr15d0rfKShYRERFZhfj4eOh0OtPjJ1WxwsPDceLECSQlJWHz5s2IjIzE3r17JU20mGQRERGRcmScjDTvasGicHJyQqVKlQAA9evXx9GjRzF//nwsXbpUsrB4upCIiIhsntFoRFZWlqRtspJFREREirGEyUjHjx+PF198ERUqVEBKSgo2bNiAPXv24Oeff5Y0LiZZREREpBwLmMIhISEBPXv2xM2bN6HX61G7dm38/PPPaNOmjaRhMcmS0alDbvjqU1/EnHLF/duOmPTZZTR+Mcn0vBDAmtn++GlDGaQm26P6s2kYMjMe5UKzVYzautgnZqPstji4nkuEJseAnLLOSOgahqwK7mqHZrXY58rxH3gBDndy8q1PfcELif0DVYjI+g1sfBTvNDlmtu7yPU90+rybShHR0/jss88U2Q+TLBllptshtEYG2nW7j6l9Q/I9v+kTX3z7uQ9GzbsK/wrZWD0rAO93D8PyPX/Dydky78NUmtil56L8gtPIqKzHjberwuDuAMc7mTC48mMvF/a5shI+DAWM/ztWOMZlwWfqVWQ00qsYlfW7eMcLb3/1iumxwSj1KG4rZxSARuK/cUbL/JvJI5+MGrRKQYNWKQU+JwSwdYUPug29hcYvPJw8bcyCq3ijTk0c+EmPiE6JCkZqnbx23kCupxYJ3cJM63LLOKsYkfVjnyvLqDc/hDtvuYtcfydk1XBVKSLbkCvscC+NfUz/jkmWSm7FOeF+giOeaZZqWuemM6JqvXSc+8ONSZYE3M48QHq4Hv6rLsA5NhkGvROSmvghuZGf2qFZLfa5inKMcN2XhNQOZQANKytyCvZMwo53ViM71x4nb/hjwb6GuJXioXZYpYcFjMlSiupTOBiNRkRHRyMkJAQuLi6oU6cONm/erHZYsruf8DC/9fQxH0/h6ZNjeo5KxuFeJnQHbiPbxxk3BlRDUmM/lN1yBR5H7qgdmtVin6vH5UgK7NIMSGvpqXYoVu3UTV9EbW+Fdze/jOk7mqOcPhkru22FqyPH0lJ+qv81j46Oxrp167BkyRJUrlwZ+/btw5tvvgkfHx+0aNHCbNusrCyzOSwev0cR0aM0AsgMcsP99hUAANnl3eB0KwP6A7eR8h8flaOzTuxz9bjtfIDMeu4wejuqHYpV+/1ysOnfMXfK4NRNP2wfsA7tqsZiy6lqKkZWmshQyQIrWflkZWVhxowZ+Pzzz9GuXTuEhoaiV69eePPNNwuccTU6OtrsnkRBQUEqRC0Nb99cAEDiHfMDYuIdR9NzVDK5Okdk+7mYrcv2c4ZDorSTzdH/sM/VYZ+QDe2pNKQ976V2KDYnJUuLq/f1CPJM+veNyeaommRdvHgR6enpaNOmDdzd3U3LmjVrEBsbm2/78ePHIykpybTEx8erELU0/Ctkw9s3B8f3/++y9rQUO/x93BXV6qepGJn1yAzxgFNCptk6p4RM5Hg9+Y7s9PTY5+pw250Io84BmfU5LkhpLo45CPJMxl0OhC86GW8QbWlUPV2Ymvpw0PcPP/yAcuXKmT1X0E0dtVrtE2/2aGky0uxw4/L/4r0V74TY0y7w8MyFb/kcdOp3Bxvn+6FcSJZpCocyfjlo/AJ/EUkhsUUAys8/A68d15Fatwy0canQHUpAQpdQtUOzWuxzFRgFXHclIi3CE7DngHe5jYg4gL0XK+Jmsjt83NPxTpOjMAgNtp+rrHZopYdRQPLTe5zCIb/q1atDq9UiLi4u3/gra3DhpCvGvF7J9Hjp5IeJZJsu9zFqXhy6DEpAZrod5o8JQmqyPWo0SMP09Zc4R5ZEsiq442afKijzQxy8frmGXG8t7nYKRmr9smqHZrXY58rT/pUGh7s5SG/tqXYoNsHPPQ0zO+yAp3MmHmS44Pi1ALy1/lU8yHD59xeTzVE1yfLw8MCoUaMwfPhwGI1GNG3aFElJSfj999+h0+kQGRmpZnglVqdxKn6+caLQ5zUaIHLMLUSOuaVcUDYmvYYX0mtwnIqS2OfKyqrrjmtf11A7DJsxdpu0t12xScL4cJG6TQuk+tWF06ZNg4+PD6Kjo3Hp0iV4enrimWeewfvvv692aERERERPTfUkS6PRYOjQoRg6dKjaoRAREZHcOBkpEREREZWE6pUsIiIisiE2dHUhK1lEREREMmAli4iIiJRjQ2OymGQRERGRcgRkSLKkbU4qPF1IREREJANWsoiIiEg5NnS6kJUsIiIiIhmwkkVERETKMRoBSHwbHKNl3laHlSwiIiIiGbCSRURERMrhmCwiIiIiKglWsoiIiEg5NlTJYpJFREREyuG9C4mIiIioJFjJIiIiIsUIYYQQ0k65IHV7UmEli4iIiEgGrGQRERGRcoSQfgyVhQ58ZyWLiIiISAasZBEREZFyhAxXF7KSRURERGQ7WMkiIiIi5RiNgEbiqwEt9OpCJllERESkHJ4uJCIiIqKSYCWLiIiIFCOMRgiJTxdyMlIiIiIiG8JKFhERESmHY7KIiIiIqCRYySIiIiLlGAWgYSWLiIiIiJ4SK1lERESkHCEASD0ZKStZRERERDaDlSwiIiJSjDAKCInHZAkLrWQxySIiIiLlCCOkP13IyUiJiIiIbAaTLCIiIlKMMApZluKIjo5GgwYN4OHhAV9fX3Tq1Annz5+X/L0yySIiIiKbsnfvXgwaNAiHDh3Cjh07kJOTg7Zt2yItLU3S/XBMFhERESnHAsZk/fTTT2aPV61aBV9fX/zxxx9o3ry5ZGGV6iQr72qC5FTLHPBmjYyZmWqHQCQ7Q3qW2iHYFE0WjytKMWQ/7Gs1r8bLRY7kty7MRQ4AIDk52Wy9VquFVqv919cnJSUBALy9vSWNSyMs9brHIrh27RqCgoLUDoOIiKhUiY+PR/ny5RXdZ2ZmJkJCQnDr1i1Z2nd3d0dqaqrZukmTJmHy5MlPfJ3RaMQrr7yCxMRE7N+/X9KYSnUlKzAwEPHx8fDw8IBGo1E7nCJLTk5GUFAQ4uPjodPp1A7HJrDPlcX+Vh77XFmltb+FEEhJSUFgYKDi+3Z2dsbly5eRnZ0tS/tCiHy5QFGqWIMGDcLp06clT7CAUp5k2dnZKZ6JS0mn05WqL6c1YJ8ri/2tPPa5skpjf+v1etX27ezsDGdnZ9X2/7jBgwdj27Zt2Ldvnyz5RKlOsoiIiIiKSwiB9957D1u2bMGePXsQEhIiy36YZBEREZFNGTRoEDZs2IBvv/0WHh4epnFier0eLi4uku2H82SpQKvVYtKkSUU6V0zSYJ8ri/2tPPa5stjfpdvixYuRlJSEiIgIBAQEmJYvv/xS0v2U6qsLiYiIiCwVK1lEREREMmCSRURERCQDJllEREREMmCSRVYtIiICw4YNUzsMIkXxc09kGZhkEREREcmASRYRERGRDJhkKeynn35C06ZN4enpiTJlyuDll19GbGys2mFZtdzcXAwePBh6vR5ly5ZFVFSUqnegt3ZGoxGzZs1CpUqVoNVqUaFCBUyfPl3tsKxWWloaevbsCXd3dwQEBGDOnDlqh2TVjEYjoqOjERISAhcXF9SpUwebN29WOyyyUEyyFJaWloYRI0bg2LFj2LlzJ+zs7NC5c2cYjUa1Q7Naq1evhoODA44cOYL58+fj448/xooVK9QOy2qNHz8eM2fORFRUFM6ePYsNGzbAz89P7bCs1ujRo7F37158++23+OWXX7Bnzx78+eefaodltaKjo7FmzRosWbIEZ86cwfDhw/Hmm29i7969aodGFoiTkars7t278PHxwalTp1CzZk21w7E6ERERSEhIwJkzZ0x3Zx83bhy+++47nD17VuXorE9KSgp8fHywaNEi9OvXT+1wrF5qairKlCmDdevW4f/+7/8AAPfv30f58uXx9ttvY968eeoGaGWysrLg7e2NX3/9FY0aNTKt79evH9LT07FhwwYVoyNLxEqWwmJiYtCtWzeEhoZCp9OhYsWKAIC4uDh1A7Nizz33nCnBAoBGjRohJiYGBoNBxais07lz55CVlYXWrVurHYpNiI2NRXZ2Nho2bGha5+3tjfDwcBWjsl4XL15Eeno62rRpA3d3d9OyZs0aDvugAvEG0Qrr0KEDgoODsXz5cgQGBsJoNKJmzZrIzs5WOzSiEpPyxqpEliY1NRUA8MMPP6BcuXJmz/EehlQQVrIUdO/ePZw/fx7//e9/0bp1a1SrVg0PHjxQOyyrd/jwYbPHhw4dQuXKlWFvb69SRNarcuXKcHFxwc6dO9UOxSaEhYXB0dHR7DP+4MEDXLhwQcWorFf16tWh1WoRFxeHSpUqmS1BQUFqh0cWiJUsBXl5eaFMmTJYtmwZAgICEBcXh3HjxqkdltWLi4vDiBEjMGDAAPz5559YuHAhr8CSibOzM8aOHYsxY8bAyckJTZo0wZ07d3DmzBn07dtX7fCsjru7O/r27YvRo0ejTJky8PX1xYQJE2Bnx9/PcvDw8MCoUaMwfPhwGI1GNG3aFElJSfj999+h0+kQGRmpdohkYZhkKcjOzg5ffPEFhgwZgpo1ayI8PBwLFixARESE2qFZtZ49eyIjIwP/+c9/YG9vj6FDh+Ltt99WOyyrFRUVBQcHB0ycOBE3btxAQEAABg4cqHZYVmv27NlITU1Fhw4d4OHhgZEjRyIpKUntsKzWtGnT4OPjg+joaFy6dAmenp545pln8P7776sdGlkgXl1IREREJAPWlImIiIhkwCSLiIiISAZMsoiIiIhkwCSLiIiISAZMsoiIiIhkwCSLiIiISAZMsoiIiIhkwCSLiIiISAZMsohsVK9evdCpUyfT44iICAwbNkzxOPbs2QONRoPExMRCt9FoNNi6dWuR25w8eTLq1q1boriuXLkCjUaDEydOlKgdIrJdTLKILEivXr2g0Wig0Wjg5OSESpUqYerUqcjNzZV939988w2mTZtWpG2LkhgREdk63ruQyMK88MILWLlyJbKysvDjjz9i0KBBcHR0xPjx4/Ntm52dDScnJ0n26+3tLUk7RET0ECtZRBZGq9XC398fwcHBeOedd/D888/ju+++A/C/U3zTp09HYGAgwsPDAQDx8fHo0qULPD094e3tjY4dO+LKlSumNg0GA0aMGAFPT0+UKVMGY8aMweO3LX38dGFWVhbGjh2LoKAgaLVaVKpUCZ999hmuXLmCli1bAgC8vLyg0WjQq1cvAIDRaER0dDRCQkLg4uKCOnXqYPPmzWb7+fHHH1GlShW4uLigZcuWZnEW1dixY1GlShW4uroiNDQUUVFRyMnJybfd0qVLERQUBFdXV3Tp0iXfjZNXrFiBatWqwdnZGVWrVsWnn35a7FiIiArDJIvIwrm4uCA7O9v0eOfOnTh//jx27NiBbdu2IScnB+3atYOHhwd+++03/P7773B3d8cLL7xget2cOXOwatUqfP7559i/fz/u37+PLVu2PHG/PXv2xMaNG7FgwQKcO3cOS5cuhbu7O4KCgvD1118DAM6fP4+bN29i/vz5AIDo6GisWbMGS5YswZkzZzB8+HC8+eab2Lt3L4CHyeCrr76KDh064MSJE+jXrx/GjRtX7D7x8PDAqlWrcPbsWcyfPx/Lly/H3Llzzba5ePEiNm3ahO+//x4//fQTjh8/jnfffdf0/Pr16zFx4kRMnz4d586dw4wZMxAVFYXVq1cXOx4iogIJIrIYkZGRomPHjkIIIYxGo9ixY4fQarVi1KhRpuf9/PxEVlaW6TVr164V4eHhwmg0mtZlZWUJFxcX8fPPPwshhAgICBCzZs0yPZ+TkyPKly9v2pcQQrRo0UIMHTpUCCHE+fPnBQCxY8eOAuPcvXu3ACAePHhgWpeZmSlcXV3FgQMHzLbt27ev6NatmxBCiPHjx4vq1aubPT927Nh8bT0OgNiyZUuhz8+ePVvUr1/f9HjSpEnC3t5eXLt2zbRu+/btws7OTty8eVMIIURYWJjYsGGDWTvTpk0TjRo1EkIIcfnyZQFAHD9+vND9EhE9CcdkEVmYbdu2wd3dHTk5OTAajejevTsmT55ser5WrVpm47BOnjyJixcvwsPDw6ydzMxMxMbGIikpCTdv3kTDhg1Nzzk4OODZZ5/Nd8owz4kTJ2Bvb48WLVoUOe6LFy8iPT0dbdq0MVufnZ2NevXqAQDOnTtnFgcANGrUqMj7yPPll19iwYIFiI2NRWpqKnJzc6HT6cy2qVChAsqVK2e2H6PRiPPnz8PDwwOxsbHo27cv+vfvb9omNzcXer2+2PEQERWESRaRhWnZsiUWL14MJycnBAYGwsHB/Gvq5uZm9jg1NRX169fH+vXr87Xl4+PzVDG4uLgU+zWpqakAgB9++MEsuQEejjOTysGDB9GjRw9MmTIF7dq1g16vxxdffIE5c+YUO9bly5fnS/rs7e0li5WIbBuTLCIL4+bmhkqVKhV5+2eeeQZffvklfH1981Vz8gQEBODw4cNo3rw5gIcVmz/++APPPPNMgdvXqlULRqMRe/fuxfPPP5/v+bxKmsFgMK2rXr06tFot4uLiCq2AVatWzTSIP8+hQ4f+/U0+4sCBAwgODsaECRNM665evZpvu7i4ONy4cQOBgYGm/djZ2SE8PBx+fn4IDAzEpUuX0KNHj2Ltn4ioqDjwnaiU69GjB8qWLYuOHTvit99+w+XLl7Fnzx4MGTIE165dAwAMHToUM2fOxNatW/H333/j3XfffeIcVxUrVkRkZCT69OmDrVu3mtrctGkTACA4OBgajQbbtm3DnTt3kJqaCg8PD4waNQrDhw/H6tWrERsbiz///BMLFy40DSYfOHAgYmJiMHr0aJw/fx4bNmzAqlWrivV+K1eujLi4OHzxxReIjY3FggULChzE7+zsjMjISJw8eRK//fYbhgwZgi5dusDf3x8AMGXKFERHR2PBggW4cOECTp06hZUrV+Ljjz8uVjxERIVhkkVUyrm6umLfvn2oUKECXn31VVSrVg19+/ZFZmamqbI1cuRIvPXWW4iMjESjRo3g4eGBzp07P7HdxYsX4/XXX8e7776LqlWron///khLSwMAlCtXDlOmTMG4cePg5+eHwYMHAwCmTZuGqKgoREdHo1q1anjhhRfwww8/ICQkBMDDcVJff/01tm7dijp16mDJkiWYMWNGsd7vK6+8guHDh2Pw4MGoW7cuDhw4gKioqHzbVapUCa+++ipeeukltG3bFrVr1zaboqFfv35YsWIFVq5ciVq1aqFFixZYtWqVKVYiopLSiMJGvhIRERHRU2Mli4iIiEgGTLKIiIiIZMAki4iIiEgGTLKIiIiIZMAki4iIiEgGTLKIiIiIZMAki4iIiEgGTLKIiIiIZMAki4iIiEgGTLKIiIiIZMAki4iIiEgG/w/pc/ZsdLFgHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(true_values, predictions)\n",
    "fig, ax = plt.subplots(figsize=(8,6), dpi=100)\n",
    "display = ConfusionMatrixDisplay(conf, display_labels=['a', 'b', 'c', 'd', 'e'])\n",
    "ax.set(title='Confusion Matrix for SAT sentence completion')\n",
    "display.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'b': 37, 'e': 34, 'a': 32, 'c': 27, 'd': 22})\n",
      "Counter({'a': 43, 'c': 33, 'e': 26, 'b': 26, 'd': 24})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(sat['ans']))\n",
    "print(Counter(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGdCAYAAAAIbpn/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaTUlEQVR4nO3df3SW9X3/8VciEFhDQkEIUKC11SM61J6yqjl6HEM65jZPOzmu6+mOzFJdHdpCnKVsBU9dPbHt8Ue1qK1TOs/KccfuWOd6Rt2YpjsW/IFrZ3Vj1HkKZ5jAqgRBCWjy/WOnOctXQAzB6/6Qx+Oc6xzvz3Xnylsuc3h63dedu66vr68vAAAFqq96AACAwRIyAECxhAwAUCwhAwAUS8gAAMUSMgBAsYQMAFAsIQMAFGtE1QMcbb29vdm2bVvGjh2burq6qscBAA5DX19fXnnllUydOjX19Qe/7nLMh8y2bdsyffr0qscAAAZh69atmTZt2kH3H/MhM3bs2CT/+wfR1NRU8TQAwOHYtWtXpk+f3v/3+MEc8yHzy5eTmpqahAwAFOatbgtxsy8AUCwhAwAUS8gAAMUSMgBAsYQMAFAsIQMAFEvIAADFEjIAQLGEDABQLCEDABRLyAAAxRIyAECxhAwAUCwhAwAUa0TVA9SS2dfcW/UIxdr4tUuqHgGAYcgVGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYtVMyNxwww2pq6vLkiVL+tf27t2bxYsXZ8KECWlsbMyCBQvS1dVV3ZAAQE2piZB58skn881vfjOnn376gPWlS5fmoYceyv3335+Ojo5s27YtF110UUVTAgC1pvKQ2b17dz75yU/mrrvuyrvf/e7+9e7u7tx999256aabMnfu3MyePTurV6/Oj370o2zYsKHCiQGAWlF5yCxevDi/8zu/k3nz5g1Y37hxY/bv3z9gfebMmZkxY0bWr19/0OP19PRk165dAzYA4Ng0ospvft999+Xpp5/Ok08++aZ9nZ2dGTVqVMaNGzdgvaWlJZ2dnQc9Znt7e770pS8N9agAQA2q7IrM1q1b87nPfS7f+c53Mnr06CE77vLly9Pd3d2/bd26dciODQDUlspCZuPGjdm+fXs+9KEPZcSIERkxYkQ6Ojpy6623ZsSIEWlpacm+ffuyc+fOAV/X1dWVyZMnH/S4DQ0NaWpqGrABAMemyl5aOv/88/PMM88MWLv00kszc+bMLFu2LNOnT8/IkSOzbt26LFiwIEmyadOmbNmyJa2trVWMDADUmMpCZuzYsZk1a9aAtXe9612ZMGFC//qiRYvS1taW8ePHp6mpKVdddVVaW1tz9tlnVzEyAFBjKr3Z963cfPPNqa+vz4IFC9LT05P58+fn9ttvr3osAKBG1FTIPProowMejx49OqtWrcqqVauqGQgAqGmV/x4ZAIDBEjIAQLGEDABQLCEDABRLyAAAxRIyAECxhAwAUCwhAwAUS8gAAMUSMgBAsYQMAFAsIQMAFEvIAADFEjIAQLGEDABQLCEDABRLyAAAxRIyAECxhAwAUCwhAwAUS8gAAMUSMgBAsYQMAFAsIQMAFEvIAADFEjIAQLGEDABQLCEDABRLyAAAxRIyAECxhAwAUCwhAwAUS8gAAMUSMgBAsYQMAFAsIQMAFEvIAADFEjIAQLGEDABQLCEDABRLyAAAxRIyAECxhAwAUCwhAwAUS8gAAMUSMgBAsYQMAFAsIQMAFEvIAADFEjIAQLFGVD0AHMiW606reoRizVj5TNUjALxjXJEBAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGAChWpSFzxx135PTTT09TU1OamprS2tqaf/iHf+jfv3fv3ixevDgTJkxIY2NjFixYkK6urgonBgBqSaUhM23atNxwww3ZuHFjnnrqqcydOzcf/ehH8+yzzyZJli5dmoceeij3339/Ojo6sm3btlx00UVVjgwA1JARVX7zCy+8cMDj66+/PnfccUc2bNiQadOm5e67786aNWsyd+7cJMnq1atzyimnZMOGDTn77LOrGBkAqCE1c4/MG2+8kfvuuy979uxJa2trNm7cmP3792fevHn9z5k5c2ZmzJiR9evXH/Q4PT092bVr14ANADg2VR4yzzzzTBobG9PQ0JDPfOYzeeCBB3Lqqaems7Mzo0aNyrhx4wY8v6WlJZ2dnQc9Xnt7e5qbm/u36dOnH+V/AwCgKpWHzMknn5wf//jHefzxx3PFFVdk4cKFee655wZ9vOXLl6e7u7t/27p16xBOCwDUkkrvkUmSUaNG5cQTT0ySzJ49O08++WS+/vWv5+Mf/3j27duXnTt3Drgq09XVlcmTJx/0eA0NDWloaDjaYwMANaDyKzL/v97e3vT09GT27NkZOXJk1q1b179v06ZN2bJlS1pbWyucEACoFZVekVm+fHkuuOCCzJgxI6+88krWrFmTRx99ND/4wQ/S3NycRYsWpa2tLePHj09TU1OuuuqqtLa2escSAJCk4pDZvn17Lrnkkrz44otpbm7O6aefnh/84Af5yEc+kiS5+eabU19fnwULFqSnpyfz58/P7bffXuXIAEANqTRk7r777kPuHz16dFatWpVVq1a9QxMBACWpuXtkAAAOl5ABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAo1oiqBwDg8HSc9+tVj1C0X/9hx5Ae7xtXPzSkxxtOrrzxwiE7lisyAECxhAwAUCwhAwAUS8gAAMUSMgBAsYQMAFAsIQMAFEvIAADFEjIAQLGEDABQrEGFzNy5c7Nz5843re/atStz58490pkAAA7LoELm0Ucfzb59+960vnfv3vzLv/zLEQ8FAHA43taHRv7bv/1b/z8/99xz6ezs7H/8xhtvZO3atXnPe94zdNMBABzC2wqZD37wg6mrq0tdXd0BX0IaM2ZMbrvttiEbDgDgUN5WyLzwwgvp6+vL+9///jzxxBOZOHFi/75Ro0Zl0qRJOe6444Z8SACAA3lbIfPe9743SdLb23tUhgEAeDveVsj8X5s3b84jjzyS7du3vylsVq5cecSDAbXhnNvOqXqEoj121WNVjwDHtEGFzF133ZUrrrgixx9/fCZPnpy6urr+fXV1dUIGAHhHDCpkvvzlL+f666/PsmXLhnoeAIDDNqjfI/Pyyy/n4osvHupZAADelkGFzMUXX5yHH354qGcBAHhbBvXS0oknnpgVK1Zkw4YNOe200zJy5MgB+z/72c8OyXAAAIcyqJD51re+lcbGxnR0dKSjo2PAvrq6OiEDALwjBhUyL7zwwlDPAQDwtg3qHhkAgFowqCsyn/rUpw65/5577hnUMAAAb8egQubll18e8Hj//v356U9/mp07dx7wwyQBAI6GQYXMAw888Ka13t7eXHHFFfnABz5wxEMBAByOIbtHpr6+Pm1tbbn55puH6pAAAIc0pDf7Pv/883n99deH8pAAAAc1qJeW2traBjzu6+vLiy++mO9///tZuHDhkAwGAPBWBhUy//qv/zrgcX19fSZOnJgbb7zxLd/RBAAwVAYVMo888shQzwEA8LYNKmR+aceOHdm0aVOS5OSTT87EiROHZCgAgMMxqJt99+zZk0996lOZMmVKzjvvvJx33nmZOnVqFi1alFdffXWoZwQAOKBBhUxbW1s6Ojry0EMPZefOndm5c2cefPDBdHR05Oqrrx7qGQEADmhQLy397d/+bb773e9mzpw5/Wu//du/nTFjxuT3f//3c8cddwzVfAAABzWoKzKvvvpqWlpa3rQ+adIkLy0BAO+YQYVMa2trrr322uzdu7d/7bXXXsuXvvSltLa2DtlwAACHMqiXlm655Zb81m/9VqZNm5YzzjgjSfKTn/wkDQ0Nefjhh4d0QACAgxlUyJx22mnZvHlzvvOd7+Q//uM/kiSf+MQn8slPfjJjxowZ0gEBAA5mUCHT3t6elpaWXHbZZQPW77nnnuzYsSPLli0bkuEAAA5lUPfIfPOb38zMmTPftP6rv/qrufPOO494KACAwzGokOns7MyUKVPetD5x4sS8+OKLRzwUAMDhGFTITJ8+PY899tib1h977LFMnTr1sI/T3t6eD3/4wxk7dmwmTZqUj33sY/0fefBLe/fuzeLFizNhwoQ0NjZmwYIF6erqGszYAMAxZlAhc9lll2XJkiVZvXp1fv7zn+fnP/957rnnnixduvRN980cSkdHRxYvXpwNGzbkH//xH7N///785m/+Zvbs2dP/nKVLl+ahhx7K/fffn46Ojmzbti0XXXTRYMYGAI4xg7rZ95prrskvfvGL/Mmf/En27duXJBk9enSWLVuW5cuXH/Zx1q5dO+Dxt7/97UyaNCkbN27Meeedl+7u7tx9991Zs2ZN5s6dmyRZvXp1TjnllGzYsCFnn332YMYHAI4Rg7oiU1dXl6985SvZsWNHNmzYkJ/85Cd56aWXsnLlyiMapru7O0kyfvz4JMnGjRuzf//+zJs3r/85M2fOzIwZM7J+/foj+l4AQPkGdUXmlxobG/PhD394SAbp7e3NkiVLcs4552TWrFlJ/vem4lGjRmXcuHEDntvS0pLOzs4DHqenpyc9PT39j3ft2jUk8wEAtWdQV2SOhsWLF+enP/1p7rvvviM6Tnt7e5qbm/u36dOnD9GEAECtqYmQufLKK/P3f//3eeSRRzJt2rT+9cmTJ2ffvn3ZuXPngOd3dXVl8uTJBzzW8uXL093d3b9t3br1aI4OAFSo0pDp6+vLlVdemQceeCD//M//nBNOOGHA/tmzZ2fkyJFZt25d/9qmTZuyZcuWg344ZUNDQ5qamgZsAMCx6YjukTlSixcvzpo1a/Lggw9m7Nix/fe9NDc3Z8yYMWlubs6iRYvS1taW8ePHp6mpKVdddVVaW1u9YwkAqDZk7rjjjiTJnDlzBqyvXr06f/RHf5Qkufnmm1NfX58FCxakp6cn8+fPz+233/4OTwoA1KJKQ6avr+8tnzN69OisWrUqq1ategcmAgBKUhM3+wIADIaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYlUaMj/84Q9z4YUXZurUqamrq8v3vve9Afv7+vqycuXKTJkyJWPGjMm8efOyefPmaoYFAGpOpSGzZ8+enHHGGVm1atUB93/1q1/NrbfemjvvvDOPP/543vWud2X+/PnZu3fvOzwpAFCLRlT5zS+44IJccMEFB9zX19eXW265JV/84hfz0Y9+NEly7733pqWlJd/73vfyB3/wB+/kqABADarZe2ReeOGFdHZ2Zt68ef1rzc3NOeuss7J+/fqDfl1PT0927do1YAMAjk01GzKdnZ1JkpaWlgHrLS0t/fsOpL29Pc3Nzf3b9OnTj+qcAEB1ajZkBmv58uXp7u7u37Zu3Vr1SADAUVKzITN58uQkSVdX14D1rq6u/n0H0tDQkKampgEbAHBsqtmQOeGEEzJ58uSsW7euf23Xrl15/PHH09raWuFkAECtqPRdS7t3787Pfvaz/scvvPBCfvzjH2f8+PGZMWNGlixZki9/+cs56aSTcsIJJ2TFihWZOnVqPvaxj1U3NABQMyoNmaeeeiq/8Ru/0f+4ra0tSbJw4cJ8+9vfzuc///ns2bMnl19+eXbu3Jlzzz03a9euzejRo6saGQCoIZWGzJw5c9LX13fQ/XV1dbnuuuty3XXXvYNTAQClqNl7ZAAA3oqQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACiWkAEAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYhURMqtWrcr73ve+jB49OmeddVaeeOKJqkcCAGpAzYfM3/zN36StrS3XXnttnn766ZxxxhmZP39+tm/fXvVoAEDFaj5kbrrpplx22WW59NJLc+qpp+bOO+/Mr/zKr+See+6pejQAoGIjqh7gUPbt25eNGzdm+fLl/Wv19fWZN29e1q9ff8Cv6enpSU9PT//j7u7uJMmuXbve8vu90fPaEU48fB3On+/b8creN4b0eMPJUJ+L1197fUiPN9wM5fnY87pzcSSG+mfjtZ5Xh/R4w8nhnItfPqevr+/QT+yrYf/93//dl6TvRz/60YD1a665pu/MM8884Ndce+21fUlsNpvNZrMdA9vWrVsP2Qo1fUVmMJYvX562trb+x729vXnppZcyYcKE1NXVVTjZkdm1a1emT5+erVu3pqmpqepxhjXnonY4F7XDuagdx8q56OvryyuvvJKpU6ce8nk1HTLHH398jjvuuHR1dQ1Y7+rqyuTJkw/4NQ0NDWloaBiwNm7cuKM14juuqamp6P8wjyXORe1wLmqHc1E7joVz0dzc/JbPqembfUeNGpXZs2dn3bp1/Wu9vb1Zt25dWltbK5wMAKgFNX1FJkna2tqycOHC/Nqv/VrOPPPM3HLLLdmzZ08uvfTSqkcDACpW8yHz8Y9/PDt27MjKlSvT2dmZD37wg1m7dm1aWlqqHu0d1dDQkGuvvfZNL5vxznMuaodzUTuci9ox3M5FXV/fW72vCQCgNtX0PTIAAIciZACAYgkZAKBYQgY4JsyZMydLliypegyozHD9GRAyAECxhAwAUCwhU+PWrl2bc889N+PGjcuECRPyu7/7u3n++eerHmvY6u3tzVe/+tWceOKJaWhoyIwZM3L99ddXPdaws2fPnlxyySVpbGzMlClTcuONN1Y90rDW29ub9vb2nHDCCRkzZkzOOOOMfPe73616rGHp9ddfz5VXXpnm5uYcf/zxWbFixVt/enThhEyN27NnT9ra2vLUU09l3bp1qa+vz+/93u+lt7e36tGGpeXLl+eGG27IihUr8txzz2XNmjXD7pcz1oJrrrkmHR0defDBB/Pwww/n0UcfzdNPP131WMNWe3t77r333tx555159tlns3Tp0vzhH/5hOjo6qh5t2Pmrv/qrjBgxIk888US+/vWv56abbspf/uVfVj3WUeUX4hXmf/7nfzJx4sQ888wzmTVrVtXjDCuvvPJKJk6cmG984xv59Kc/XfU4w9bu3bszYcKE/PVf/3UuvvjiJMlLL72UadOm5fLLL88tt9xS7YDDTE9PT8aPH59/+qd/GvAZeJ/+9Kfz6quvZs2aNRVON7zMmTMn27dvz7PPPpu6urokyRe+8IX83d/9XZ577rmKpzt6XJGpcZs3b84nPvGJvP/9709TU1Pe9773JUm2bNlS7WDD0L//+7+np6cn559/ftWjDGvPP/989u3bl7POOqt/bfz48Tn55JMrnGr4+tnPfpZXX301H/nIR9LY2Ni/3XvvvV4Gr8DZZ5/dHzFJ0trams2bN+eNN96ocKqjq+Y/a2m4u/DCC/Pe9743d911V6ZOnZre3t7MmjUr+/btq3q0YWfMmDFVjwA1Z/fu3UmS73//+3nPe94zYN9w+awfquWKTA37xS9+kU2bNuWLX/xizj///Jxyyil5+eWXqx5r2DrppJMyZsyYrFu3rupRhrUPfOADGTlyZB5//PH+tZdffjn/+Z//WeFUw9epp56ahoaGbNmyJSeeeOKAbfr06VWPN+z835+LJNmwYUNOOumkHHfccRVNdPS5IlPD3v3ud2fChAn51re+lSlTpmTLli35whe+UPVYw9bo0aOzbNmyfP7zn8+oUaNyzjnnZMeOHXn22WezaNGiqscbNhobG7No0aJcc801mTBhQiZNmpQ///M/T329/y+rwtixY/Onf/qnWbp0aXp7e3Puueemu7s7jz32WJqamrJw4cKqRxxWtmzZkra2tvzxH/9xnn766dx2223H/Lv6hEwNq6+vz3333ZfPfvazmTVrVk4++eTceuutmTNnTtWjDVsrVqzIiBEjsnLlymzbti1TpkzJZz7zmarHGna+9rWvZffu3bnwwgszduzYXH311enu7q56rGHrL/7iLzJx4sS0t7fnv/7rvzJu3Lh86EMfyp/92Z9VPdqwc8kll+S1117LmWeemeOOOy6f+9zncvnll1c91lHlXUsAQLFciwUAiiVkAIBiCRkAoFhCBgAolpABAIolZACAYgkZAKBYQgYAKJaQAQCKJWQAgGIJGQCgWEIGACjW/wOGucRhfgrCiAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=predictions)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Results\n",
    "Our model does not perform that well currently. We hypothesize that this is due to both the complexity of the words in the SAT question dataset as well as the size of our input dataset. Our input dataset is only comprised of around 600,000 sentences. Additionally, our input dataset comes from spoken lecture transcripts. While these transcripts should be on fairly complex topics, they still contain mostly spoken language. The SAT question dataset prompts are more complex than the language spoken in our input dataset. This leads to a mismatch between our corpus and training data where most of our n-grams either have low counts or do not exist in our corpus. This could be remedied by expanding the size of our input dataset and thusly our corpus. The research paper that our test dataset came from compiled their corpus on over 1.1 billion words in newspaper articles. Even with this large increase in corpus size they still only achieved a prediction accuracy of just over 50% on the testing dataset. This implies that the test dataset is fairly difficult to get high accuracy scores on.\n",
    "\n",
    "Note that we did not perform cross validation on our system. The primary reason for this is due to cross validation not making sense in our case. We have created a corpus and are trying to compute the accuracy of our corpus using a test set. As we are not directly training a model, it does not make sense to perform cross validation only over our test set.\n",
    "\n",
    "## Additionl Dataset Note\n",
    "[Note] One additional area of improvement that we should also test is improving the size of our test set. I found another dataset that will work for this from the paper [SC-Ques: A Sentence Completion Question Dataset for English as a Second Language Learners](https://arxiv.org/abs/2206.12036). They provided a [link to their code and their data](https://github.com/ai4ed/SC-Ques) for research purposes. This, in turn, gave a link to a [dropbox containing their data](https://www.dropbox.com/s/lzznin2hxt6rmft/SC-Ques.tar.gz?dl=0). The data that we would be looking to use to expand our training set would be found in test.jsons and train.jsons. These two files have been preprocessed in the SC-Ques-Preprocessing.ipynb notebook and saved to the individual processed_data_idx.csv files. They were stored as multiple files due to space limitations with GitHub repositories.\n",
    "\n",
    "The below section is used to read in and join each of the processed_data_idx.csv files. There should be no need to run the SC-Ques-Preprocessing.ipynb script and is only included for posterity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets\\SC-Ques\\processed_data_0.csv\n",
      "Datasets\\SC-Ques\\processed_data_1.csv\n",
      "Datasets\\SC-Ques\\processed_data_10.csv\n",
      "Datasets\\SC-Ques\\processed_data_11.csv\n",
      "Datasets\\SC-Ques\\processed_data_12.csv\n",
      "Datasets\\SC-Ques\\processed_data_13.csv\n",
      "Datasets\\SC-Ques\\processed_data_14.csv\n",
      "Datasets\\SC-Ques\\processed_data_15.csv\n",
      "Datasets\\SC-Ques\\processed_data_16.csv\n",
      "Datasets\\SC-Ques\\processed_data_17.csv\n",
      "Datasets\\SC-Ques\\processed_data_18.csv\n",
      "Datasets\\SC-Ques\\processed_data_19.csv\n",
      "Datasets\\SC-Ques\\processed_data_2.csv\n",
      "Datasets\\SC-Ques\\processed_data_3.csv\n",
      "Datasets\\SC-Ques\\processed_data_4.csv\n",
      "Datasets\\SC-Ques\\processed_data_5.csv\n",
      "Datasets\\SC-Ques\\processed_data_6.csv\n",
      "Datasets\\SC-Ques\\processed_data_7.csv\n",
      "Datasets\\SC-Ques\\processed_data_8.csv\n",
      "Datasets\\SC-Ques\\processed_data_9.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ans</th>\n",
       "      <th>blanks</th>\n",
       "      <th>a)</th>\n",
       "      <th>b)</th>\n",
       "      <th>c)</th>\n",
       "      <th>d)</th>\n",
       "      <th>e)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The plane is scheduled to arrive _____ because...</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>The plane is scheduled to arrive latest becaus...</td>\n",
       "      <td>The plane is scheduled to arrive later because...</td>\n",
       "      <td>The plane is scheduled to arrive late because ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_____ he was preparing food for tomorrow's pa...</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>Because he was preparing food for tomorrow's p...</td>\n",
       "      <td>While he was preparing food for tomorrow's par...</td>\n",
       "      <td>If he was preparing food for tomorrow's party,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't like the people _____ may get angry ea...</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>I don't like the people who may get angry easily.</td>\n",
       "      <td>I don't like the people that may get angry eas...</td>\n",
       "      <td>I don't like the people which may get angry ea...</td>\n",
       "      <td>I don't like the people both may get angry eas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop making so much noise. It is _____ to the ...</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>Stop making so much noise. It is comfortable t...</td>\n",
       "      <td>Stop making so much noise. It is relaxed to th...</td>\n",
       "      <td>Stop making so much noise. It is harmful to th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles Dickens _____ a lot of novels.</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>Charles Dickens write a lot of novels.</td>\n",
       "      <td>Charles Dickens wrote a lot of novels.</td>\n",
       "      <td>Charles Dickens writes a lot of novels.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14452</th>\n",
       "      <td>If you keep _____ this, your English handwriti...</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>If you keep do this, your English handwriting ...</td>\n",
       "      <td>If you keep doing this, your English handwriti...</td>\n",
       "      <td>If you keep to do this, your English handwriti...</td>\n",
       "      <td>If you keep does this, your English handwritin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>Two days later, the fighting between the two c...</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>Two days later, the fighting between the two c...</td>\n",
       "      <td>Two days later, the fighting between the two c...</td>\n",
       "      <td>Two days later, the fighting between the two c...</td>\n",
       "      <td>Two days later, the fighting between the two c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14454</th>\n",
       "      <td>What he had said about the incident and done w...</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>What he had said about the incident and done w...</td>\n",
       "      <td>What he had said about the incident and done w...</td>\n",
       "      <td>What he had said about the incident and done w...</td>\n",
       "      <td>What he had said about the incident and done w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14455</th>\n",
       "      <td>Get up quickly, Lisa! You have _____ time to h...</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>Get up quickly, Lisa! You have a few time to h...</td>\n",
       "      <td>Get up quickly, Lisa! You have many time to ha...</td>\n",
       "      <td>Get up quickly, Lisa! You have no time to have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14456</th>\n",
       "      <td>I'm sure more waste _____ because we're going ...</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure more waste recycles because we're goi...</td>\n",
       "      <td>I'm sure more waste is recycling because we're...</td>\n",
       "      <td>I'm sure more waste is recycled because we're ...</td>\n",
       "      <td>I'm sure more waste will be recycled because w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289148 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question ans  blanks  \\\n",
       "0      The plane is scheduled to arrive _____ because...   c       1   \n",
       "1       _____ he was preparing food for tomorrow's pa...   b       1   \n",
       "2      I don't like the people _____ may get angry ea...   d       1   \n",
       "3      Stop making so much noise. It is _____ to the ...   c       1   \n",
       "4                Charles Dickens _____ a lot of novels.    b       1   \n",
       "...                                                  ...  ..     ...   \n",
       "14452  If you keep _____ this, your English handwriti...   b       1   \n",
       "14453  Two days later, the fighting between the two c...   c       1   \n",
       "14454  What he had said about the incident and done w...   b       1   \n",
       "14455  Get up quickly, Lisa! You have _____ time to h...   c       1   \n",
       "14456  I'm sure more waste _____ because we're going ...   d       1   \n",
       "\n",
       "                                                      a)  \\\n",
       "0      The plane is scheduled to arrive latest becaus...   \n",
       "1      Because he was preparing food for tomorrow's p...   \n",
       "2      I don't like the people who may get angry easily.   \n",
       "3      Stop making so much noise. It is comfortable t...   \n",
       "4                 Charles Dickens write a lot of novels.   \n",
       "...                                                  ...   \n",
       "14452  If you keep do this, your English handwriting ...   \n",
       "14453  Two days later, the fighting between the two c...   \n",
       "14454  What he had said about the incident and done w...   \n",
       "14455  Get up quickly, Lisa! You have a few time to h...   \n",
       "14456  I'm sure more waste recycles because we're goi...   \n",
       "\n",
       "                                                      b)  \\\n",
       "0      The plane is scheduled to arrive later because...   \n",
       "1      While he was preparing food for tomorrow's par...   \n",
       "2      I don't like the people that may get angry eas...   \n",
       "3      Stop making so much noise. It is relaxed to th...   \n",
       "4                 Charles Dickens wrote a lot of novels.   \n",
       "...                                                  ...   \n",
       "14452  If you keep doing this, your English handwriti...   \n",
       "14453  Two days later, the fighting between the two c...   \n",
       "14454  What he had said about the incident and done w...   \n",
       "14455  Get up quickly, Lisa! You have many time to ha...   \n",
       "14456  I'm sure more waste is recycling because we're...   \n",
       "\n",
       "                                                      c)  \\\n",
       "0      The plane is scheduled to arrive late because ...   \n",
       "1      If he was preparing food for tomorrow's party,...   \n",
       "2      I don't like the people which may get angry ea...   \n",
       "3      Stop making so much noise. It is harmful to th...   \n",
       "4                Charles Dickens writes a lot of novels.   \n",
       "...                                                  ...   \n",
       "14452  If you keep to do this, your English handwriti...   \n",
       "14453  Two days later, the fighting between the two c...   \n",
       "14454  What he had said about the incident and done w...   \n",
       "14455  Get up quickly, Lisa! You have no time to have...   \n",
       "14456  I'm sure more waste is recycled because we're ...   \n",
       "\n",
       "                                                      d)  e)  \n",
       "0                                                    NaN NaN  \n",
       "1                                                    NaN NaN  \n",
       "2      I don't like the people both may get angry eas... NaN  \n",
       "3                                                    NaN NaN  \n",
       "4                                                    NaN NaN  \n",
       "...                                                  ...  ..  \n",
       "14452  If you keep does this, your English handwritin... NaN  \n",
       "14453  Two days later, the fighting between the two c... NaN  \n",
       "14454  What he had said about the incident and done w... NaN  \n",
       "14455                                                NaN NaN  \n",
       "14456  I'm sure more waste will be recycled because w... NaN  \n",
       "\n",
       "[289148 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = Path(\"Datasets\\\\SC-Ques\")\n",
    "sc_ques = pd.DataFrame()\n",
    "for data_path in directory_path.glob(\"**\\\\Processed_data_*.csv\"):\n",
    "    print(data_path)\n",
    "    data = pd.read_csv(data_path)\n",
    "    sc_ques = pd.concat([sc_ques, data])\n",
    "sc_ques = sc_ques.drop(columns=['Unnamed: 0'])\n",
    "sc_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['b']\n",
      "True Value: ['b']\n",
      "[ACCURACY]     : 1.000\n",
      "[PRECISION]    : 1.000\n",
      "[RECALL]       : 1.000\n",
      "[F1-SCORE]     : 1.000\n"
     ]
    }
   ],
   "source": [
    "test = sc_ques.iloc[4]\n",
    "prediction = [predict(test)]\n",
    "print(\"Prediction: %s\" % prediction)\n",
    "true_value = [test['ans']]\n",
    "print(\"True Value: %s\" % true_value)\n",
    "score(true_value, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sc_ques.progress_apply(lambda row: predict(row), axis=1)\n",
    "predictions\n",
    "true_values = sc_ques['ans']\n",
    "score(true_values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(true_values, predictions)\n",
    "fig, ax = plt.subplots(figsize=(8,6), dpi=100)\n",
    "display = ConfusionMatrixDisplay(conf, display_labels=['a', 'b', 'c', 'd', 'e'])\n",
    "ax.set(title='Confusion Matrix for SAT sentence completion')\n",
    "display.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
