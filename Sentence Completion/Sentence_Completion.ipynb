{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Completion\n",
    "This notebook is used for a final project as a part of the CS 4980 Natural Language Processing course at the Milwaukee School of Engineering during the spring term of 2023. This notebook was created by [Grant Fass](grantfass@gmail.com) and [Nicholas Kaja](kajan@msoe.edu). The following notebook will explore the problem of natural language sentence completion.\n",
    "\n",
    "Natural language sentence completion involves determining what word best fits in a blank present in a sentence. This type of question is typically found on the Scholastic Aptitude Test (SAT). It is useful because it can measure the performance of a language model (LM) on questions that educational experts deem important. LMs that perform well on this type of problem will likely perform better on broader tasks.\n",
    "\n",
    "The primary method for forming a sentence completion model is to compute the probability of each possible sentence tehn choose the most probable option. This probability computation can be done using n-grams, Latent Semantic Analysis (LSA), and Syntactic Dependency Trees. Some research has also been done into combining these with methods of preserving long-range dependencies in the sentences. Of these options, N-grams is one of the easiest starting points due to its ease of implementation and understanding. N-grams also allow for sufficient variations over the base model such as different N-gram algorithms, different values of N, and different methods of tokenization.\n",
    "\n",
    "We will be constructing our models from a dataset of Khan Academy lecture transcripts. This dataset was scraped using BeautifulSoup during January of 2023 by Nicholas Kaja as a part of a senior design project. The performance of our model will be evaluated on a [SAT Question Dataset](https://github.com/ctr4si/sentence-completion/tree/master/data/completion). After evaluation, we plan to take our best performing model and apply it to sentence generation. This will allow us to get a better feel for how well it performs. Once our model is working, we also plan to implement some additional features such as Named Entity Recognition (NER). If there is enough time we also plan to investigate using the [OpenAI tokenizer](https://platform.openai.com/tokenizer) instead of the [NLTK Word Tokenizer](https://www.nltk.org/api/nltk.tokenize.html) or the [SpaCy Tokenizer](https://spacy.io/api/tokenizer). The OpenAI tokenizer has a [python package found on github](https://github.com/openai/tiktoken).\n",
    "\n",
    "For more information please see the Data Collection And Processing document as well as the Project Background document. Both of these documents can be found in the repository under the Sentence Completion directory.\n",
    "\n",
    "## Imports\n",
    "Below are sample imports based on other NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "import contractions\n",
    "import unidecode\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download([\n",
    "\"names\",\n",
    "\"stopwords\",\n",
    "\"state_union\",\n",
    "\"twitter_samples\",\n",
    "\"movie_reviews\",\n",
    "\"averaged_perceptron_tagger\",\n",
    "\"vader_lexicon\",\n",
    "\"punkt\",\n",
    "])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading  \n",
    "Combine all domains into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "computing = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Computing.csv\")\n",
    "computing = computing.dropna()\n",
    "\n",
    "economics = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Economics.csv\")\n",
    "economics = economics.dropna()\n",
    "\n",
    "humanities = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Humanities.csv\")\n",
    "humanities = humanities.dropna()\n",
    "\n",
    "math = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Math.csv\")\n",
    "math = math.dropna()\n",
    "\n",
    "science = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Science.csv\")\n",
    "science = science.dropna()\n",
    "\n",
    "khan_dfs = [computing, economics, humanities, math, science]\n",
    "khan = pd.concat(khan_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Decided to just remove the first sentence from every transcript. This guarantees that we catch all of the tags like \"[Instructor]\" or \"- Speaker 1:\"  \n",
    "Most of the first sentences are greetings / introdcutions - not very useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_sentence(doc):\n",
    "    \"\"\"\n",
    "    This removes the first sentence of a document. We use this to remove all narrator / speaker tags, and\n",
    "    to remove unnecessary introductory sentences that most transcripts have\n",
    "    \"\"\"\n",
    "    return ' '.join(nltk.sent_tokenize(doc)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bracket_tags(doc):\n",
    "    \"\"\"\n",
    "    This gets rid of any remaining tags in the transcript such as (music) or [clicking]\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\s{2,}\", \" \", re.sub(r\"[\\(\\[\\{][^\\)\\]\\}]*[\\)\\]\\}]\", \"\", doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "khan['clean_transcript'] = khan['transcript'].apply(remove_first_sentence).apply(remove_bracket_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8261/8261 [01:07<00:00, 122.32it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "corpus = khan['clean_transcript'].values\n",
    "for document in tqdm(corpus):\n",
    "    tokens += nltk.word_tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "quadgrams = list(ngrams(tokens, n))\n",
    "fdist = nltk.FreqDist(quadgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = \"_____\" # SAT Dataset uses 5 underscores as the mask token\n",
    "\n",
    "def fill(fdist: nltk.FreqDist, prompt: str, candidates: list, mask: str=MASK, verbose: bool=False):\n",
    "    \"\"\"\n",
    "    Returns the token from the candidates list that is most likely to fill in the <MASK> of the prompt\n",
    "    based on the frequency distribution of the ngrams model\n",
    "\n",
    "            Parameters:\n",
    "                    fdist (nltk.FreqDist): The frequency distributions of the ngram model\n",
    "                    prompt (str): The prompt string. Must include a <MASK> token\n",
    "                    candidates (list): A list of candidates to potentially fill the <MASK> token\n",
    "                    mask (str): The mask token used by the prompt\n",
    "                    verbose (bool): Whether to print the sliding window grams\n",
    "\n",
    "            Returns:\n",
    "                    candidate (str): The candidate highest probability (frequency) to fill in the <MASK> token\n",
    "    \"\"\"\n",
    "    prompt_tokens = nltk.word_tokenize(prompt)\n",
    "    if mask not in prompt_tokens:\n",
    "        raise ValueError(f\"Prompt doesn't include mask token: {mask}\")\n",
    "    mask_index = prompt_tokens.index(mask)\n",
    "\n",
    "    probs = {}\n",
    "    for candidate in candidates:\n",
    "        context_probs = []\n",
    "        for i in range(n):        \n",
    "            context = tuple(prompt_tokens[max(0,mask_index-n+i+1):mask_index] + \\\n",
    "                            [candidate] + \\\n",
    "                            prompt_tokens[mask_index+1:min(mask_index+i+1,len(prompt_tokens))])\n",
    "            context_probs.append(fdist[context])\n",
    "            if len(context) == n and verbose:\n",
    "                print(context, fdist[context])\n",
    "\n",
    "        probs[candidate] = 0\n",
    "        for p in context_probs:\n",
    "            probs[candidate] += p\n",
    "            \n",
    "    return max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('you', 'do', \"n't\", 'want') 113\n",
      "('do', \"n't\", 'want', 'to') 898\n",
      "(\"n't\", 'want', 'to', 'happen') 0\n",
      "('you', 'do', \"n't\", 'expect') 1\n",
      "('do', \"n't\", 'expect', 'to') 1\n",
      "(\"n't\", 'expect', 'to', 'happen') 0\n",
      "('you', 'do', \"n't\", 'need') 56\n",
      "('do', \"n't\", 'need', 'to') 88\n",
      "(\"n't\", 'need', 'to', 'happen') 0\n",
      "('you', 'do', \"n't\", 'like') 20\n",
      "('do', \"n't\", 'like', 'to') 17\n",
      "(\"n't\", 'like', 'to', 'happen') 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'want'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"This is something that you don't _____ to happen\"\n",
    "candidates = ['want','expect','need','like']\n",
    "\n",
    "fill(fdist, question, candidates, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT = pd.read_csv(\"Datasets\\\\SAT_Question_Dataset.csv\")\n",
    "SAT = SAT[SAT['blanks'] == 1].reset_index(drop=True) # Filtering to only single blank sentences right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_token(masked, original, mask=MASK):\n",
    "    tokens = nltk.word_tokenize(original)\n",
    "    masked_tokens = nltk.word_tokenize(masked)\n",
    "    \n",
    "    result = tokens[masked_tokens.index(mask)]\n",
    "    if result in ['a','an']:\n",
    "        result = tokens[masked_tokens.index(mask) + 1]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in ['a','b','c','d','e']:\n",
    "    SAT[letter] = SAT.apply(lambda x: get_answer_token(x['question'], x[letter+')']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ans</th>\n",
       "      <th>question</th>\n",
       "      <th>a)</th>\n",
       "      <th>b)</th>\n",
       "      <th>c)</th>\n",
       "      <th>d)</th>\n",
       "      <th>e)</th>\n",
       "      <th>year</th>\n",
       "      <th>sec</th>\n",
       "      <th>num</th>\n",
       "      <th>diff</th>\n",
       "      <th>blanks</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>During the 1990's, Shanghai benefited from an ...</td>\n",
       "      <td>During the 1990's, Shanghai benefited from an ...</td>\n",
       "      <td>During the 1990's, Shanghai benefited from an ...</td>\n",
       "      <td>During the 1990's, Shanghai benefited from an ...</td>\n",
       "      <td>During the 1990's, Shanghai benefited from an ...</td>\n",
       "      <td>During the 1990's, Shanghai benefited from an ...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>intransigence</td>\n",
       "      <td>plenitude</td>\n",
       "      <td>desecration</td>\n",
       "      <td>stagnation</td>\n",
       "      <td>renaissance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>Luisa worked with extreme precision, _____ tha...</td>\n",
       "      <td>Luisa worked with extreme precision, a meticul...</td>\n",
       "      <td>Luisa worked with extreme precision, an effron...</td>\n",
       "      <td>Luisa worked with extreme precision, an inhibi...</td>\n",
       "      <td>Luisa worked with extreme precision, a litigio...</td>\n",
       "      <td>Luisa worked with extreme precision, an impetu...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>meticulousness</td>\n",
       "      <td>effrontery</td>\n",
       "      <td>inhibition</td>\n",
       "      <td>litigiousness</td>\n",
       "      <td>impetuousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>The crafty child tricked his innocent brother,...</td>\n",
       "      <td>The crafty child tricked his innocent brother,...</td>\n",
       "      <td>The crafty child tricked his innocent brother,...</td>\n",
       "      <td>The crafty child tricked his innocent brother,...</td>\n",
       "      <td>The crafty child tricked his innocent brother,...</td>\n",
       "      <td>The crafty child tricked his innocent brother,...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>guileless</td>\n",
       "      <td>intrusive</td>\n",
       "      <td>astute</td>\n",
       "      <td>opportunistic</td>\n",
       "      <td>circumspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>e</td>\n",
       "      <td>Ellen Ochoa's _____ with the apparatus in the ...</td>\n",
       "      <td>Ellen Ochoa's compromise with the apparatus in...</td>\n",
       "      <td>Ellen Ochoa's humility with the apparatus in t...</td>\n",
       "      <td>Ellen Ochoa's machinations with the apparatus ...</td>\n",
       "      <td>Ellen Ochoa's synergy with the apparatus in th...</td>\n",
       "      <td>Ellen Ochoa's deftness with the apparatus in t...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>compromise</td>\n",
       "      <td>humility</td>\n",
       "      <td>machinations</td>\n",
       "      <td>synergy</td>\n",
       "      <td>deftness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>d</td>\n",
       "      <td>In 1916 Yellowstone National Park had only 25 ...</td>\n",
       "      <td>In 1916 Yellowstone National Park had only 25 ...</td>\n",
       "      <td>In 1916 Yellowstone National Park had only 25 ...</td>\n",
       "      <td>In 1916 Yellowstone National Park had only 25 ...</td>\n",
       "      <td>In 1916 Yellowstone National Park had only 25 ...</td>\n",
       "      <td>In 1916 Yellowstone National Park had only 25 ...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>dispersed</td>\n",
       "      <td>mediated</td>\n",
       "      <td>attenuated</td>\n",
       "      <td>burgeoned</td>\n",
       "      <td>reconciled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id ans                                           question  \\\n",
       "0   4   e  During the 1990's, Shanghai benefited from an ...   \n",
       "1   6   a  Luisa worked with extreme precision, _____ tha...   \n",
       "2   7   a  The crafty child tricked his innocent brother,...   \n",
       "3   8   e  Ellen Ochoa's _____ with the apparatus in the ...   \n",
       "4   9   d  In 1916 Yellowstone National Park had only 25 ...   \n",
       "\n",
       "                                                  a)  \\\n",
       "0  During the 1990's, Shanghai benefited from an ...   \n",
       "1  Luisa worked with extreme precision, a meticul...   \n",
       "2  The crafty child tricked his innocent brother,...   \n",
       "3  Ellen Ochoa's compromise with the apparatus in...   \n",
       "4  In 1916 Yellowstone National Park had only 25 ...   \n",
       "\n",
       "                                                  b)  \\\n",
       "0  During the 1990's, Shanghai benefited from an ...   \n",
       "1  Luisa worked with extreme precision, an effron...   \n",
       "2  The crafty child tricked his innocent brother,...   \n",
       "3  Ellen Ochoa's humility with the apparatus in t...   \n",
       "4  In 1916 Yellowstone National Park had only 25 ...   \n",
       "\n",
       "                                                  c)  \\\n",
       "0  During the 1990's, Shanghai benefited from an ...   \n",
       "1  Luisa worked with extreme precision, an inhibi...   \n",
       "2  The crafty child tricked his innocent brother,...   \n",
       "3  Ellen Ochoa's machinations with the apparatus ...   \n",
       "4  In 1916 Yellowstone National Park had only 25 ...   \n",
       "\n",
       "                                                  d)  \\\n",
       "0  During the 1990's, Shanghai benefited from an ...   \n",
       "1  Luisa worked with extreme precision, a litigio...   \n",
       "2  The crafty child tricked his innocent brother,...   \n",
       "3  Ellen Ochoa's synergy with the apparatus in th...   \n",
       "4  In 1916 Yellowstone National Park had only 25 ...   \n",
       "\n",
       "                                                  e)  year  sec  num diff  \\\n",
       "0  During the 1990's, Shanghai benefited from an ...  2001    1    4    3   \n",
       "1  Luisa worked with extreme precision, an impetu...  2001    1    6    3   \n",
       "2  The crafty child tricked his innocent brother,...  2001    1    7    3   \n",
       "3  Ellen Ochoa's deftness with the apparatus in t...  2001    1    8    5   \n",
       "4  In 1916 Yellowstone National Park had only 25 ...  2001    1    9    5   \n",
       "\n",
       "   blanks               a           b             c              d  \\\n",
       "0       1   intransigence   plenitude   desecration     stagnation   \n",
       "1       1  meticulousness  effrontery    inhibition  litigiousness   \n",
       "2       1       guileless   intrusive        astute  opportunistic   \n",
       "3       1      compromise    humility  machinations        synergy   \n",
       "4       1       dispersed    mediated    attenuated      burgeoned   \n",
       "\n",
       "               e  \n",
       "0    renaissance  \n",
       "1  impetuousness  \n",
       "2    circumspect  \n",
       "3       deftness  \n",
       "4     reconciled  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for idx, record in SAT.iterrows():\n",
    "    candidates = record[['a','b','c','d','e']].values\n",
    "    prompt = record['question']\n",
    "    \n",
    "    pred_word = fill(fdist, prompt, candidates)\n",
    "    answer = ['a','b','c','d','e'][np.where(candidates == pred_word)[0][0]]\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23809523809523808"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(answers) == SAT['ans']) # Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.238095\n",
       "c    0.226190\n",
       "b    0.190476\n",
       "e    0.178571\n",
       "d    0.166667\n",
       "Name: ans, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAT['ans'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=answers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the model isn't familiar with a lot of these words and phrases, so it defaults to the first answer most of the time. As a result, the accuracy is pretty much just the percentage of questions with the answer a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
