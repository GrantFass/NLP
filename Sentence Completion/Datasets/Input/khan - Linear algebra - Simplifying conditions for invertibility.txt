Well the whole premise of the
last series of videos was really just trying to get at
trying to figure out whether some transformation T-- let's
have some transformation that is a mapping from, let's say
it's a mapping from Rn to Rm, --the whole question is,
is T invertible. And we showed several videos
ago that a function, and a transformation is really just a
function, that a function is invertible if it meets
two conditions. So invertible. So I don't have to keep writing
the word over again. You have to have
two conditions. It has to be onto or essentially
it has to map to every member of your codomain
and it also has to be one-to-one. Another way of saying one-to-one
is that every member of your codomain is
mapped to by at most one member of your domain. And we did several videos where
we thought well if we had a transformation, a linear
transformation, that's defined by a matrix, A, where this would
be an m-by-n matrix, we said that this is going to be
met if the rank-- This is only met if the rank of A is equal to
the number of rows in your transformation matrix
is equal to m. And in the last video I just
showed that this is only true if every one of your column
vectors are linearly independent or that they all
are basis vectors for your column space or that the rank
of your matrix it has to be equal to n. Now in order for something to
be invertible, in order for the transformation to be
invertible, both of these things have to be true. Your rank of A has to be equal
to m and your rank of A has to be equal to n. So in order to be invertible,
a couple of things have to happen. In order to be invertible your
rank of your transformation matrix has to be equal to m,
which has to be equal to n. So m has to be equal to n. So we have an interesting
condition. You have to have a
square matrix. Your matrix has to be n-by-n. That's what this implies. If both of these are true, then
m has to be equal n and you're dealing with
a square matrix. Even more, you're dealing with
the square matrix where every one of the columns are
linearly independent, so this is our A. A looks like this. A1, A2, all the way to An. Since the rank of A is equal to
n, and this is of course an n-by-n matrix. We just said that this has to
be the case because its rank has to be equal to m, which is
the number of rows, and its rank has to be equal to n,
which is the number of columns, so the rows and columns
have to be the same. But the fact that your rank
is equal to the number of columns, that means that all
of your column vectors are bases for your column space, or
that if you put them into reduced row echelon form, what
are you going to get? Well all of these guys are basis
vectors so they're all going to be associated with
pivot vectors or they're all going to be associated
with pivot columns. So this is going to be 1, 0,
bunch of 0's, and then you're going to have a 0, 1, a bunch
of 0's like this. They're all going to be
associated with pivot columns when you go into reduced
row echelon form. So all of them are
pivot columns. It's an n-by-n matrix. So what is an n-by-n
matrix where every column is a pivot column? What is an n-by-n matrix? Let me write this. So you have an n. So the reduced row echelon form
of A has to be equal to an n-by-n matrix, cause A is
n-by-n, where every column is a linearly independent
pivot column. And I mean by definition of
reduced row echelon form you can't have the same pivot
column twice where every column is a linearly independent
pivot column. It's a little bit redundant, but
I think you get the idea. So what is an n-by-n matrix
where every column is a linearly independent
pivot column? Well that is just a matrix that
has 1's down the diagonal and everything else is a 0. Or, you've seen this matrix
before, this is just an n-by-n identity matrix or the identity
matrix on n or on Rn. So if you multiply this matrix
times any member of Rn, you're just going to get that
matrix again. But this is interesting. We now have a pretty usable
condition for invertibility. We can say that the
transformation T that is a mapping from Rn to-- well it
has to map to the same dimension space so
from Rn to Rn. It's equal to some square matrix
n-by-n, it has to be an n-by-n matrix, times our
vectors in our domain. And it's only going to be
invertible if the reduced row echelon form of our
transformation matrix is equal to the identity matrix on n. I mean I could have written an
m here and I could've said this is an m-by-n matrix, but
the only way that this is going to be true is if
this is also an n and this is also an m. But maybe I could leave
them there. Let me leave those
m's there because that's the big takeaway. The big takeaway is that in
order for the transformation matrix to be invertible, the
only way it's invertible is if the reduced row echelon form of
our transformation matrix is equal to an n-by-n
identity matrix. The identity matrix is always
going to be n-by-n. So that's a big takeaway. Now we'll use that in the future
to actually solve for transformations or solve for
inverses of transformations.